{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "70734137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import altair as alt\n",
    "alt.data_transformers.enable(\"vegafusion\")\n",
    "from typing import Dict, List, Any, Optional\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\n",
    "    \"mps\" if torch.backends.mps.is_available() \n",
    "    else \"cuda\" if torch.cuda.is_available() \n",
    "    else \"cpu\"\n",
    ")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "c4636c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 3]"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pl.read_parquet('../data/processed/train_cg_32_200.parquet')\n",
    "str_seq = train_df.row(0, named=True)['window_seq']\n",
    "vocab = {'A':0, 'T':1, 'C':2, 'G':3}\n",
    "[vocab.get(char) for char in str_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "4c2396ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'window_fi': 30.789639956541873, 'window_fp': 21.96058935632102, 'window_ri': 30.19122800377587, 'window_rp': 22.001033021052258} {'window_fi': 24.00485941139194, 'window_fp': 11.301933232238992, 'window_ri': 23.627035898853727, 'window_rp': 11.337388102877114}\n"
     ]
    }
   ],
   "source": [
    "def compute_normalization_stats(df):\n",
    "    kinetic_features = ['window_fi', 'window_fp', 'window_ri', 'window_rp']\n",
    "    means = {col: df[col].explode().mean() for col in kinetic_features}\n",
    "    stds = {col: df[col].explode().explode().std() for col in kinetic_features}\n",
    "    return means, stds\n",
    "train_means, train_stds = compute_normalization_stats(train_df)\n",
    "print(train_means, train_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "e2058e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MethylDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for metylation data stored in a parquet file\n",
    "    Reads data using polars and converts samples to pytorch tensors on get_item call\n",
    "    Nucleotide sequence is one-hot encoded\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path: Path, \n",
    "                 transform=None, \n",
    "                 means: Optional[Dict[str, float]] = train_means, \n",
    "                 stds: Optional[Dict[str, float]] = train_stds):\n",
    "        '''\n",
    "        Arguments:\n",
    "        data_path: the path for the parquet file that contains either the training or test data (pos and neg)\n",
    "        transform: an optional transform callable on a single sample\n",
    "        '''\n",
    "        self.tranform = transform\n",
    "        self.means = means\n",
    "        self.stds = stds\n",
    "\n",
    "        try:\n",
    "             self.data = pl.read_parquet(data_path)[:500000]\n",
    "        except:\n",
    "             print(f\"failed to read data given path: {data_path}\")\n",
    "             self.data = pl.DataFrame()\n",
    "\n",
    "        self._dataset_len = len(self.data)\n",
    "        self.vocab = {'A':0, 'T':1, 'C':2, 'G':3}\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.kinetic_features = ['fi', 'fp', 'ri', 'rp']\n",
    "\n",
    "    def __len__(self):\n",
    "          return self._dataset_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "         if idx >= len(self):\n",
    "              raise IndexError(\"Index out of range\")\n",
    "         sample = self.data.row(idx, named=True)\n",
    "         # sequence data (requires one-hot encoding)\n",
    "         str_seq = sample['window_seq']\n",
    "         int_seq_tensor = torch.tensor([self.vocab.get(char) for char in str_seq], dtype=torch.long)\n",
    "         seq_tensor = F.one_hot(int_seq_tensor, num_classes=self.vocab_size)\n",
    "         # kinetic data\n",
    "         fi_tensor = (torch.tensor(sample['window_fi'], dtype=torch.long) - self.means['window_fi'])/self.stds['window_fi']\n",
    "         fp_tensor = (torch.tensor(sample['window_fp'], dtype=torch.long) - self.means['window_fp'])/self.stds['window_fp']\n",
    "         ri_tensor = (torch.tensor(sample['window_ri'], dtype=torch.long) - self.means['window_ri'])/self.stds['window_ri']\n",
    "         rp_tensor = (torch.tensor(sample['window_rp'], dtype=torch.long) - self.means['window_rp'])/self.stds['window_rp']\n",
    "         label_tensor = torch.tensor(sample['label'], dtype=torch.long) \n",
    "         \n",
    "         return {\n",
    "              'seq': seq_tensor,\n",
    "              'fi': fi_tensor,\n",
    "              'fp': fp_tensor,\n",
    "              'ri': ri_tensor,\n",
    "              'rp': rp_tensor,\n",
    "              'label': label_tensor\n",
    "              }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "542b46f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MethylDataset('../data/processed/train_cg_32_10000.parquet')\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "291377e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.503004, 500000)"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.data['label'].mean(), len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "95376c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(766)"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_list = np.array([len(train_ds.data.row(i, named=True)['window_fi']) for i in range(len(train_ds))])\n",
    "np.argmin(len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "88af216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MethylCNN(nn.Module):\n",
    "    def __init__(self, sequence_length: int = 32, in_channels:int = 8, num_classes: int = 2):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.sequence_length = sequence_length\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Convolution layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
    "\n",
    "        # calculate fc layer input with dummy passthrough\n",
    "        fc_input_features = self._get_conv_output_size(sequence_length)\n",
    "\n",
    "        # Linear layers\n",
    "        self.fc1 = nn.Linear(in_features=fc_input_features, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.fc3 = nn.Linear(in_features=32, out_features=num_classes)\n",
    "\n",
    "    def _extract_features(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool1d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool1d(x, kernel_size=2, stride=2)\n",
    "\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool1d(x, kernel_size=2, stride=2)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def _get_conv_output_size(self, sequence_length: int) -> int:\n",
    "        \"\"\"\n",
    "        Calculates the flattened output size of the convolutional layers\n",
    "        by performing a forward pass on random data of the right shape. \n",
    "        \"\"\"\n",
    "        dummy_input = torch.randn(1, self.in_channels, sequence_length)\n",
    "        output = self._extract_features(dummy_input)\n",
    "        return output.numel()\n",
    "\n",
    "    def forward(self, batch: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        # Assuming batch['seq'] is [B, L, 4]\n",
    "        seq = batch['seq'].permute(0, 2, 1) # -> [B, 4, L]\n",
    "        fi = batch['fi'].unsqueeze(1)      # -> [B, 1, L]\n",
    "        fp = batch['fp'].unsqueeze(1)       # -> [B, 1, L]\n",
    "        ri = batch['ri'].unsqueeze(1)       # -> [B, 1, L]\n",
    "        rp = batch['rp'].unsqueeze(1)       # -> [B, 1, L]\n",
    "        \n",
    "        # the input is a dictionary, so convert to a tensor\n",
    "        x = torch.cat([seq, fi, fp, ri, rp], dim=1).to(self.conv1.weight.dtype) # -> [B, 8, L]\n",
    "        \n",
    "        x = self._extract_features(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        logits = self.fc3(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "2a634821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 58/15625 [00:00<01:42, 152.54it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [32] at entry 0 and [0] at entry 11",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[573]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m):  \u001b[38;5;66;03m# loop over the dataset multiple times\u001b[39;00m\n\u001b[32m     12\u001b[39m     running_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# get the inputs; data is a list of [inputs, labels]\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torch-methyl/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torch-methyl/lib/python3.11/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torch-methyl/lib/python3.11/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torch-methyl/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torch-methyl/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:398\u001b[39m, in \u001b[36mdefault_collate\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault_collate\u001b[39m(batch):\n\u001b[32m    338\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    339\u001b[39m \u001b[33;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[32m    340\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m \u001b[33;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torch-methyl/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:171\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections.abc.MutableMapping):\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The mapping type may have extra properties, so we can't just\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# use `type(data)(...)` to create the new mapping.\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Create a clone and update it if the mapping type is mutable.\u001b[39;00m\n\u001b[32m    169\u001b[39m     clone = copy.copy(elem)\n\u001b[32m    170\u001b[39m     clone.update(\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m         \u001b[43m{\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m            \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melem\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    177\u001b[39m     )\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m clone\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torch-methyl/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:172\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections.abc.MutableMapping):\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The mapping type may have extra properties, so we can't just\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# use `type(data)(...)` to create the new mapping.\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Create a clone and update it if the mapping type is mutable.\u001b[39;00m\n\u001b[32m    169\u001b[39m     clone = copy.copy(elem)\n\u001b[32m    170\u001b[39m     clone.update(\n\u001b[32m    171\u001b[39m         {\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m             key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem\n\u001b[32m    176\u001b[39m         }\n\u001b[32m    177\u001b[39m     )\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m clone\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torch-methyl/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:155\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torch-methyl/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:272\u001b[39m, in \u001b[36mcollate_tensor_fn\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    270\u001b[39m     storage = elem._typed_storage()._new_shared(numel, device=elem.device)\n\u001b[32m    271\u001b[39m     out = elem.new(storage).resize_(\u001b[38;5;28mlen\u001b[39m(batch), *\u001b[38;5;28mlist\u001b[39m(elem.size()))\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: stack expects each tensor to be equal size, but got [32] at entry 0 and [0] at entry 11"
     ]
    }
   ],
   "source": [
    "model = MethylCNN(sequence_length=32)\n",
    "model.to(device) \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "\n",
    "epoch_losses = []\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(tqdm(train_dl), 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        labels = batch.pop('label').to(device)\n",
    "        inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    avg_epoch_loss = running_loss/len(train_dl)\n",
    "    epoch_losses.append(avg_epoch_loss)\n",
    "    print(avg_epoch_loss)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db55dd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2136, -0.3909],\n",
      "        [-0.1507,  1.0480],\n",
      "        [-0.6870,  1.2956],\n",
      "        [ 0.8742, -0.1396],\n",
      "        [-0.4239,  1.1524],\n",
      "        [ 0.2829,  0.3885],\n",
      "        [ 0.0895,  0.5631],\n",
      "        [ 1.0709, -0.3407],\n",
      "        [ 0.4605,  0.3100],\n",
      "        [ 1.3321, -0.2390],\n",
      "        [ 0.8626, -0.1533],\n",
      "        [-0.2730,  1.2336],\n",
      "        [-0.5103,  1.2349],\n",
      "        [-0.4987,  1.2338],\n",
      "        [ 0.5909,  0.2851],\n",
      "        [ 0.5141,  0.1391]], device='mps:0') tensor([0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    batch = next(iter(train_dl))\n",
    "    labels = batch.pop('label').to(device)\n",
    "    inputs: Dict[str, torch.Tensor] = {\n",
    "                k: v.to(device) for k, v in batch.items()\n",
    "            }\n",
    "\n",
    "    print(model(inputs), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5bbc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-952511942c8642fe990041449155ae33.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-952511942c8642fe990041449155ae33.vega-embed details,\n",
       "  #altair-viz-952511942c8642fe990041449155ae33.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-952511942c8642fe990041449155ae33\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-952511942c8642fe990041449155ae33\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-952511942c8642fe990041449155ae33\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"$schema\": \"https://vega.github.io/schema/vega/v5.json\", \"data\": [{\"name\": \"source_0\", \"values\": [{\"batch\": 0, \"loss\": 0.6510689421257062}, {\"batch\": 1, \"loss\": 0.5765380420745947}, {\"batch\": 2, \"loss\": 0.5384889079125179}, {\"batch\": 3, \"loss\": 0.5167749639250274}, {\"batch\": 4, \"loss\": 0.5030916146488271}]}, {\"name\": \"source_0_x_domain_batch\", \"values\": [{\"min\": 0, \"max\": 4}]}, {\"name\": \"source_0_y_domain_loss\", \"values\": [{\"min\": 0.5030916146488271, \"max\": 0.6510689421257062}]}], \"marks\": [{\"type\": \"symbol\", \"name\": \"marks\", \"from\": {\"data\": \"source_0\"}, \"encode\": {\"update\": {\"y\": {\"field\": \"loss\", \"scale\": \"y\"}, \"opacity\": {\"value\": 0.4}, \"x\": {\"field\": \"batch\", \"scale\": \"x\"}, \"shape\": {\"value\": \"circle\"}, \"fill\": {\"value\": \"#4c78a8\"}}}, \"style\": [\"circle\"]}], \"scales\": [{\"name\": \"x\", \"type\": \"linear\", \"domain\": [{\"signal\": \"(data(\\\"source_0_x_domain_batch\\\")[0] || {}).min\"}, {\"signal\": \"(data(\\\"source_0_x_domain_batch\\\")[0] || {}).max\"}], \"range\": [0, {\"signal\": \"width\"}], \"zero\": true, \"nice\": true}, {\"name\": \"y\", \"type\": \"linear\", \"domain\": [{\"signal\": \"(data(\\\"source_0_y_domain_loss\\\")[0] || {}).min\"}, {\"signal\": \"(data(\\\"source_0_y_domain_loss\\\")[0] || {}).max\"}], \"range\": [{\"signal\": \"height\"}, 0], \"zero\": true, \"nice\": true}], \"axes\": [{\"scale\": \"x\", \"domain\": false, \"grid\": true, \"maxExtent\": 0, \"minExtent\": 0, \"ticks\": false, \"zindex\": 0, \"orient\": \"bottom\", \"tickCount\": {\"signal\": \"ceil(width/40)\"}, \"aria\": false, \"labels\": false, \"gridScale\": \"y\"}, {\"scale\": \"y\", \"minExtent\": 0, \"ticks\": false, \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"labels\": false, \"aria\": false, \"orient\": \"left\", \"domain\": false, \"gridScale\": \"x\", \"zindex\": 0, \"grid\": true, \"maxExtent\": 0}, {\"scale\": \"x\", \"orient\": \"bottom\", \"labelOverlap\": true, \"labelFlush\": true, \"tickCount\": {\"signal\": \"ceil(width/40)\"}, \"grid\": false, \"zindex\": 0, \"title\": \"batch\"}, {\"scale\": \"y\", \"orient\": \"left\", \"grid\": false, \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"title\": \"loss\", \"labelOverlap\": true, \"zindex\": 0}], \"style\": \"cell\", \"background\": \"white\", \"padding\": 5, \"width\": 500, \"height\": 500}, {\"mode\": \"vega\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df = pl.DataFrame({\n",
    "    'batch': np.arange(len(epoch_losses)),\n",
    "    'loss' : epoch_losses\n",
    "})\n",
    "\n",
    "alt.Chart(loss_df).mark_circle(opacity=0.4).encode(\n",
    "    alt.X('batch'),\n",
    "    alt.Y('loss')\n",
    ").properties(\n",
    "    width=500,\n",
    "    height=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d52776",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = MethylDataset('../data/processed/test_cg_32_200.parquet')\n",
    "test_dl = DataLoader(test_ds, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6764fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MethylCNN(\n",
      "  (conv1): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a778b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model: nn.Module,\n",
    "    data_loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device,\n",
    ") -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    running_loss: float = 0.0\n",
    "    correct_predictions: int = 0\n",
    "    total_samples: int = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader):\n",
    "            labels: torch.Tensor = batch.pop(\"label\").to(device)\n",
    "            inputs: Dict[str, torch.Tensor] = {\n",
    "                k: v.to(device) for k, v in batch.items()\n",
    "            }\n",
    "\n",
    "            logits: torch.Tensor = model(inputs)\n",
    "            loss: torch.Tensor = criterion(logits, labels)\n",
    "\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "\n",
    "            _, predicted = torch.max(logits.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss: float = running_loss / total_samples\n",
    "    epoch_acc: float = correct_predictions / total_samples\n",
    "    return {\"loss\": epoch_loss, \"accuracy\": epoch_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0211d8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1755/1755 [00:03<00:00, 475.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.5112555802679415, 'accuracy': 0.7486821484541958}"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model, test_dl, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcabc49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1755"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e463b529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-methyl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
