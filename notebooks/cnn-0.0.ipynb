{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 725,
   "id": "70734137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mps\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import altair as alt\n",
    "alt.data_transformers.enable(\"vegafusion\")\n",
    "\n",
    "from typing import Dict, Optional\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\n",
    "    \"mps\" if torch.backends.mps.is_available() \n",
    "    else \"cuda\" if torch.cuda.is_available() \n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f'using {device}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "id": "c4636c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pl.read_parquet('../data/processed/train_cg_32_200.parquet')\n",
    "str_seq = train_df.row(0, named=True)['seq']\n",
    "vocab = {'A':0, 'T':1, 'C':2, 'G':3}\n",
    "# [vocab.get(char) for char in str_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "id": "4c2396ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fi': 30.789639956541873, 'fp': 21.96058935632102, 'ri': 30.19122800377587, 'rp': 22.001033021052258} {'fi': 24.00485941139194, 'fp': 11.301933232238992, 'ri': 23.627035898853727, 'rp': 11.337388102877114}\n"
     ]
    }
   ],
   "source": [
    "def compute_normalization_stats(df):\n",
    "    kinetic_features = ['fi', 'fp', 'ri', 'rp']\n",
    "    means = {col: df[col].explode().mean() for col in kinetic_features}\n",
    "    stds = {col: df[col].explode().explode().std() for col in kinetic_features}\n",
    "    return means, stds\n",
    "train_means, train_stds = compute_normalization_stats(train_df)\n",
    "print(train_means, train_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2058e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MethylDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for metylation data stored in a parquet file\n",
    "    Reads data using polars and converts samples to pytorch tensors on get_item call\n",
    "    Nucleotide sequence is one-hot encoded\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path: Path, \n",
    "                 transform=None, \n",
    "                 means: Optional[Dict[str, float]] = train_means, \n",
    "                 stds: Optional[Dict[str, float]] = train_stds):\n",
    "        '''\n",
    "        Arguments:\n",
    "        data_path: the path for the parquet file that contains either the training or test data (pos and neg)\n",
    "        transform: an optional transform callable on a single sample\n",
    "        '''\n",
    "        self.tranform = transform\n",
    "        self.means = means\n",
    "        self.stds = stds\n",
    "\n",
    "        try:\n",
    "             self.data = pl.read_parquet(data_path)#[:500000] # can shorten the dataset here\n",
    "        except:\n",
    "             print(f\"failed to read data given path: {data_path}\")\n",
    "             self.data = pl.DataFrame()\n",
    "\n",
    "        self._dataset_len = len(self.data)\n",
    "        self.vocab = {'A':0, 'T':1, 'C':2, 'G':3}\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.kinetic_features = ['fi', 'fp', 'ri', 'rp']\n",
    "\n",
    "    def __len__(self):\n",
    "          return self._dataset_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "         if idx >= len(self):\n",
    "              raise IndexError(\"Index out of range\")\n",
    "         sample = self.data.row(idx, named=True)\n",
    "         # sequence data (requires one-hot encoding)\n",
    "         str_seq = sample['window_seq']\n",
    "         int_seq_tensor = torch.tensor([self.vocab.get(char) for char in str_seq], dtype=torch.long)\n",
    "         seq_tensor = F.one_hot(int_seq_tensor, num_classes=self.vocab_size)\n",
    "         # kinetic data\n",
    "         fi_tensor = (torch.tensor(sample['window_fi'], dtype=torch.long) - self.means['window_fi'])/self.stds['window_fi']\n",
    "         fp_tensor = (torch.tensor(sample['window_fp'], dtype=torch.long) - self.means['window_fp'])/self.stds['window_fp']\n",
    "         ri_tensor = (torch.tensor(sample['window_ri'], dtype=torch.long) - self.means['window_ri'])/self.stds['window_ri']\n",
    "         rp_tensor = (torch.tensor(sample['window_rp'], dtype=torch.long) - self.means['window_rp'])/self.stds['window_rp']\n",
    "         label_tensor = torch.tensor(sample['label'], dtype=torch.long) \n",
    "         \n",
    "         return {\n",
    "              'seq': seq_tensor,\n",
    "              'fi': fi_tensor,\n",
    "              'fp': fp_tensor,\n",
    "              'ri': ri_tensor,\n",
    "              'rp': rp_tensor,\n",
    "              'label': label_tensor\n",
    "              }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542b46f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MethylDataset('../data/processed/train_cg_32_200.parquet')\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291377e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5005877533573184, 28073)"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check that we have an even distribution of positives/negatives\n",
    "train_ds.data['label'].mean(), len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95376c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(32), np.int64(0))"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_list = np.array([len(train_ds.data.row(i, named=True)['window_fi']) for i in range(len(train_ds))])\n",
    "np.min(len_list),np.argmin(len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88af216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MethylCNN(nn.Module):\n",
    "    def __init__(self, sequence_length: int = 32, in_channels:int = 8, num_classes: int = 2):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.sequence_length = sequence_length\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Convolution layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=5, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "\n",
    "        # calculate fc layer input with dummy passthrough\n",
    "        fc_input_features = self._get_conv_output_size(sequence_length)\n",
    "\n",
    "        # Linear layers\n",
    "        self.fc1 = nn.Linear(in_features=fc_input_features, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.fc3 = nn.Linear(in_features=32, out_features=num_classes)\n",
    "\n",
    "    def _extract_features(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool1d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool1d(x, kernel_size=2, stride=2)\n",
    "\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool1d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool1d(x, kernel_size=2, stride=2)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def _get_conv_output_size(self, sequence_length: int) -> int:\n",
    "        \"\"\"\n",
    "        Calculates the flattened output size of the convolutional layers\n",
    "        by performing a forward pass on random data of the right shape. \n",
    "        \"\"\"\n",
    "        dummy_input = torch.randn(1, self.in_channels, sequence_length)\n",
    "        output = self._extract_features(dummy_input)\n",
    "        return output.numel()\n",
    "\n",
    "    def forward(self, batch: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        # Assuming batch['seq'] is [B, L, 4]\n",
    "        seq = batch['seq'].permute(0, 2, 1) # -> [B, 4, L]\n",
    "        fi = batch['fi'].unsqueeze(1)      # -> [B, 1, L]\n",
    "        fp = batch['fp'].unsqueeze(1)       # -> [B, 1, L]\n",
    "        ri = batch['ri'].unsqueeze(1)       # -> [B, 1, L]\n",
    "        rp = batch['rp'].unsqueeze(1)       # -> [B, 1, L]\n",
    "        \n",
    "        # the input is a dictionary, so convert to a tensor\n",
    "        x = torch.cat([seq, fi, fp, ri, rp], dim=1).to(self.conv1.weight.dtype) # -> [B, 8, L]\n",
    "        \n",
    "        x = self._extract_features(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        logits = self.fc3(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a634821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878/878 [00:05<00:00, 165.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6670178258473346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878/878 [00:05<00:00, 160.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5740320823390826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878/878 [00:05<00:00, 162.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.538193117648974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878/878 [00:05<00:00, 157.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.51678927809611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878/878 [00:05<00:00, 162.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5028713926978426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878/878 [00:05<00:00, 159.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4909298901270082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878/878 [00:06<00:00, 135.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4839951020913678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878/878 [00:06<00:00, 130.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4754205398719783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878/878 [00:05<00:00, 148.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47028748000333415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878/878 [00:05<00:00, 150.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46363196163894377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878/878 [00:05<00:00, 165.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45956149539466873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878/878 [00:05<00:00, 162.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4544522482774524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878/878 [00:05<00:00, 158.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44936236543983965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878/878 [00:05<00:00, 156.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44493991314753856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878/878 [00:05<00:00, 158.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4416767768137547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878/878 [00:05<00:00, 165.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43695019696391524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878/878 [00:05<00:00, 166.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4339111344146294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878/878 [00:05<00:00, 157.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42813630558227894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878/878 [00:05<00:00, 162.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4237457142637911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878/878 [00:05<00:00, 166.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4212837063607702\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = MethylCNN(sequence_length=32)\n",
    "model.to(device) \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "\n",
    "epoch_losses = []\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(tqdm(train_dl), 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        labels = batch.pop('label').to(device)\n",
    "        inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    avg_epoch_loss = running_loss/len(train_dl)\n",
    "    epoch_losses.append(avg_epoch_loss)\n",
    "    print(avg_epoch_loss)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db55dd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3210e+00, -1.2048e+00],\n",
      "        [-1.4418e+00,  1.8942e+00],\n",
      "        [ 1.3418e+00, -1.2189e+00],\n",
      "        [ 6.5940e-01, -4.0190e-01],\n",
      "        [ 2.8530e-02,  3.0001e-01],\n",
      "        [ 1.1157e+00, -9.8696e-01],\n",
      "        [-4.7015e-01,  8.3435e-01],\n",
      "        [-2.7035e-01,  5.7051e-01],\n",
      "        [ 1.5051e+00, -1.4167e+00],\n",
      "        [-1.3569e+00,  1.7928e+00],\n",
      "        [ 7.2928e-01, -5.5585e-01],\n",
      "        [-5.3890e-01,  9.2664e-01],\n",
      "        [-2.1676e-01,  5.5794e-01],\n",
      "        [ 1.6882e+00, -1.5067e+00],\n",
      "        [ 2.1765e-01,  4.4489e-02],\n",
      "        [-2.5903e-01,  6.1229e-01],\n",
      "        [ 4.9300e-01, -2.4271e-01],\n",
      "        [ 4.3383e-01, -1.8364e-01],\n",
      "        [ 1.5126e+00, -1.4137e+00],\n",
      "        [-3.6736e-01,  7.2130e-01],\n",
      "        [ 1.8543e-01,  6.9353e-02],\n",
      "        [ 8.6622e-01, -6.8850e-01],\n",
      "        [ 9.4464e-01, -7.2723e-01],\n",
      "        [ 1.6170e-01,  1.0657e-01],\n",
      "        [ 1.5844e-03,  3.0410e-01],\n",
      "        [-1.7206e-01,  4.7717e-01],\n",
      "        [ 1.2194e+00, -1.1332e+00],\n",
      "        [-1.2380e+00,  1.6782e+00],\n",
      "        [ 1.3391e+00, -1.2247e+00],\n",
      "        [ 1.2608e+00, -1.1665e+00],\n",
      "        [-1.4147e+00,  1.8596e+00],\n",
      "        [-1.4330e-02,  2.8735e-01]], device='mps:0') tensor([0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
      "        1, 1, 0, 1, 0, 0, 1, 1], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    batch = next(iter(train_dl))\n",
    "    labels = batch.pop('label').to(device)\n",
    "    inputs: Dict[str, torch.Tensor] = {\n",
    "                k: v.to(device) for k, v in batch.items()\n",
    "            }\n",
    "\n",
    "    print(model(inputs), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5bbc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-9c5c85f7a4ec47aca9631af5dc245912.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-9c5c85f7a4ec47aca9631af5dc245912.vega-embed details,\n",
       "  #altair-viz-9c5c85f7a4ec47aca9631af5dc245912.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-9c5c85f7a4ec47aca9631af5dc245912\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-9c5c85f7a4ec47aca9631af5dc245912\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-9c5c85f7a4ec47aca9631af5dc245912\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"$schema\": \"https://vega.github.io/schema/vega/v5.json\", \"data\": [{\"name\": \"source_0\", \"values\": [{\"batch\": 0, \"loss\": 0.6670178258473346}, {\"batch\": 1, \"loss\": 0.5740320823390826}, {\"batch\": 2, \"loss\": 0.538193117648974}, {\"batch\": 3, \"loss\": 0.51678927809611}, {\"batch\": 4, \"loss\": 0.5028713926978426}, {\"batch\": 5, \"loss\": 0.4909298901270082}, {\"batch\": 6, \"loss\": 0.4839951020913678}, {\"batch\": 7, \"loss\": 0.4754205398719783}, {\"batch\": 8, \"loss\": 0.47028748000333415}, {\"batch\": 9, \"loss\": 0.46363196163894377}, {\"batch\": 10, \"loss\": 0.45956149539466873}, {\"batch\": 11, \"loss\": 0.4544522482774524}, {\"batch\": 12, \"loss\": 0.44936236543983965}, {\"batch\": 13, \"loss\": 0.44493991314753856}, {\"batch\": 14, \"loss\": 0.4416767768137547}, {\"batch\": 15, \"loss\": 0.43695019696391524}, {\"batch\": 16, \"loss\": 0.4339111344146294}, {\"batch\": 17, \"loss\": 0.42813630558227894}, {\"batch\": 18, \"loss\": 0.4237457142637911}, {\"batch\": 19, \"loss\": 0.4212837063607702}]}, {\"name\": \"source_0_x_domain_batch\", \"values\": [{\"min\": 0, \"max\": 19}]}, {\"name\": \"source_0_y_domain_loss\", \"values\": [{\"min\": 0.4212837063607702, \"max\": 0.6670178258473346}]}], \"marks\": [{\"type\": \"line\", \"name\": \"marks\", \"from\": {\"data\": \"source_0\"}, \"sort\": {\"field\": \"x\"}, \"encode\": {\"update\": {\"x\": {\"field\": \"batch\", \"scale\": \"x\"}, \"y\": {\"field\": \"loss\", \"scale\": \"y\"}, \"stroke\": {\"value\": \"#4c78a8\"}, \"defined\": {\"signal\": \"isValid(datum[\\\"batch\\\"]) && isFinite(+datum[\\\"batch\\\"]) && isValid(datum[\\\"loss\\\"]) && isFinite(+datum[\\\"loss\\\"])\"}, \"opacity\": {\"value\": 0.4}}}, \"style\": [\"line\"]}], \"scales\": [{\"name\": \"x\", \"type\": \"linear\", \"domain\": [{\"signal\": \"(data(\\\"source_0_x_domain_batch\\\")[0] || {}).min\"}, {\"signal\": \"(data(\\\"source_0_x_domain_batch\\\")[0] || {}).max\"}], \"range\": [0, {\"signal\": \"width\"}], \"zero\": false, \"nice\": true}, {\"name\": \"y\", \"type\": \"linear\", \"domain\": [{\"signal\": \"(data(\\\"source_0_y_domain_loss\\\")[0] || {}).min\"}, {\"signal\": \"(data(\\\"source_0_y_domain_loss\\\")[0] || {}).max\"}], \"range\": [{\"signal\": \"height\"}, 0], \"nice\": true, \"zero\": true}], \"axes\": [{\"scale\": \"x\", \"maxExtent\": 0, \"ticks\": false, \"zindex\": 0, \"orient\": \"bottom\", \"tickCount\": {\"signal\": \"ceil(width/40)\"}, \"grid\": true, \"gridScale\": \"y\", \"aria\": false, \"domain\": false, \"labels\": false, \"minExtent\": 0}, {\"scale\": \"y\", \"zindex\": 0, \"aria\": false, \"orient\": \"left\", \"ticks\": false, \"grid\": true, \"minExtent\": 0, \"domain\": false, \"maxExtent\": 0, \"gridScale\": \"x\", \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"labels\": false}, {\"scale\": \"x\", \"labelOverlap\": true, \"labelFlush\": true, \"tickCount\": {\"signal\": \"ceil(width/40)\"}, \"title\": \"batch\", \"zindex\": 0, \"grid\": false, \"orient\": \"bottom\"}, {\"scale\": \"y\", \"labelOverlap\": true, \"title\": \"loss\", \"zindex\": 0, \"grid\": false, \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"orient\": \"left\"}], \"style\": \"cell\", \"width\": 500, \"background\": \"white\", \"height\": 500, \"padding\": 5}, {\"mode\": \"vega\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df = pl.DataFrame({\n",
    "    'batch': np.arange(len(epoch_losses)),\n",
    "    'loss' : epoch_losses\n",
    "})\n",
    "\n",
    "alt.Chart(loss_df).mark_line(opacity=0.4).encode(\n",
    "    alt.X('batch'),\n",
    "    alt.Y('loss')\n",
    ").properties(\n",
    "    width=500,\n",
    "    height=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d52776",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = MethylDataset('../data/processed/test_cg_32_200.parquet')\n",
    "test_dl = DataLoader(test_ds, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6764fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MethylCNN(\n",
      "  (conv1): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(1,))\n",
      "  (conv3): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv4): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a778b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model: nn.Module,\n",
    "    data_loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device,\n",
    ") -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    running_loss: float = 0.0\n",
    "    correct_predictions: int = 0\n",
    "    total_samples: int = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader):\n",
    "            labels: torch.Tensor = batch.pop(\"label\").to(device)\n",
    "            inputs: Dict[str, torch.Tensor] = {\n",
    "                k: v.to(device) for k, v in batch.items()\n",
    "            }\n",
    "\n",
    "            logits: torch.Tensor = model(inputs)\n",
    "            loss: torch.Tensor = criterion(logits, labels)\n",
    "\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "\n",
    "            _, predicted = torch.max(logits.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss: float = running_loss / total_samples\n",
    "    epoch_acc: float = correct_predictions / total_samples\n",
    "    return {\"loss\": epoch_loss, \"accuracy\": epoch_acc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aeec77",
   "metadata": {},
   "source": [
    "### test 1: \n",
    "0.815 test set accuracy\n",
    "### test 2: \n",
    "move from adam -> adam2, change conv1 to size 5\n",
    "0.808 test set accuracy \n",
    "0.807 train set accuracy (why is this lower than the train set accuracy??)\n",
    "### test 3: \n",
    "add another convolutional layer (64-> 128)\n",
    "test set: 0.79\n",
    "train set: 0.79\n",
    "### test 34 \n",
    "added 5 more epochs of training\n",
    "test set: 0.818\n",
    "train set: 0.825\n",
    "So this was 10 epochs with batch size 32, on the 10k reads datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcabc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1755 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1755/1755 [00:03<00:00, 454.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.4925670400442332, 'accuracy': 0.7700527140618322}"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model, test_dl, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0211d8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878/878 [00:03<00:00, 249.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.4169128398978833, 'accuracy': 0.8102803405407331}"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model, train_dl, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e463b529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff18263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-methyl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
