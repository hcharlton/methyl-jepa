{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6wW5t8FyWrK0",
      "metadata": {
        "id": "6wW5t8FyWrK0"
      },
      "source": [
        "# Background\n",
        "\n",
        "Methylation is a modification of DNA that controls gene expression. There are many different types of methylation, but one of the most prominent is methylation at CpG sites (see [this wikipedia article](https://en.wikipedia.org/wiki/CpG_site)). When a CpG site is methylated, it is chemically changed, meaning that the biophysical properties of that section of the DNA molecule are slightly different than \"canonical structure.\" Therefore, if we had data which contained a signal of the properties of the molecule, we could detect methylation.\n",
        "\n",
        "The data that I'm using in this notebook was sequenced using PacBio Sequell technology. Here's PacBio's [advertisement](https://youtu.be/_lD8JyAbwEo?si=zILsY74u6tJyXsmJ)... it's not the most detailed, and fails to mention that the data you get from the system also includes the temporal information from the polymerase that does the sequencing. These include how long the light flash lasted (from the nucleotide incorporation), and the time until the next light flash. This is included for both the forward and reverse strand of the molecule that was sequenced.\n",
        "\n",
        "The polymerase spans around 8 nucleotides, and since methylation adds some resistance, there is a difference in these signals for the methylated an unmethylated CpG sites. The issue of course, is that the kinetics are not just affected by methylation, but also by regular nucleotide context. So if we want to predict methlyation based on kinetics, the model needs to learn how to deconflate the kinetics signal associated with methylation from the affect that different nucleotides have on the polymerase behaviour.\n",
        "\n",
        "PacBio actually already figured this out with [primrose](https://github.com/mattoslmp/primrose). But I thought it would be a nice exercise before setting off into uncharted territory of genetics models to\n",
        "\n",
        "1. reimplement primrose with a CNN as PacBio did\n",
        "\n",
        "2. Pretrain with contrastive learning and try to beat that with a classification downstream task.\n",
        "\n",
        "Yes, I should get to the science, but I also know that deep learning is hard even on easy problems, so I think I'll spend a bit more time on problems I know are solvable: this model did not learn at all until I added a final linear layer for classification, which I did on a hunch. Another reason that reimplementing Primrose is interesting is that the source code for Primrose is not public.\n",
        "\n",
        "## Dataset\n",
        "Regarding the dataset that's present here: I filtered 32 base windows centered on CpG sites. They come from two [BAM](https://en.wikipedia.org/wiki/BAM_(file_format)) files, one artificially fully methylated and the other artificially fully unmethylated. I don't have enough background in geneitcs/chemistry to know whether this imbues the data with some artifacts that make a model non-generalizeable to real data, but it's implied that PacBio believes that it's generalizeable (PrimRose and its successors run on-device to make methylation calls).\n",
        "\n",
        "I really don't like interacting with BAM files, so I made a script to take out the CpG sites and place them into parquet columnar files. Below is a summary of the features:\n",
        "\n",
        "  ``read_name``: The unique identifier for the read. This corresponds to one zero-mode-waveguide's measurements in the video.\n",
        "\n",
        "  ``cg_pos``: The position in the read, indexed from 0, where the CpG site occurs\n",
        "\n",
        "  ``seq``: The 32 bp window of nucleotides. This is a consensus as a result of between 5 and 30 passes over the same section of DNA by the polymerase. PacBio is not specific about how it chooses which base to call for each position based on the 5-30 passes. But someo of them are called by the google DeepConsensus algorithm, which has a little more background.\n",
        "\n",
        "  ``fi``: The interpulse duration at each position in the window. This is how long it took the polymerase to reach the next base. This is for the forward strand. A 'kinetics' feature.\n",
        "\n",
        "  ``fp``: The pulse width at each position in the window. This is how long the light flash lasted. A 'kinetics' feature.\n",
        "\n",
        "  ``ri``: same as window_fi, but the reverse strand. A 'kinetics' feature.\n",
        "\n",
        "  ``rp``: same as window_fp, but the reverse strand. A 'kinetics' feature.\n",
        "\n",
        "Note: Units for the kinetics features (window_fi, window_fp, etc) are in \"frames\" so we can think of it as an arbitrary time unit.\n",
        "\n",
        "# Implementation plan\n",
        "## Now\n",
        "### Architecture\n",
        "The model should take a  (Channels, Features, Context)=(1,8,32) tensor and make a binary prediction about the methylation status. 4 of the features are one-hot encoded nucleotides, and the other 4 are the kinetic features as listed above.  At first shis should just be a convolutional model, with a linear classification head. To start with, I used 200 reads of data (about 8k CpG training samples), and then moved to 10k reads of data (1.3m CpG training samples). A read has c. 12k bases each, but CpG sites are under-represented in comparison to what we'd expect randomly since they have a higher mutation rate (due to their methylation).\n",
        "### Results\n",
        "The model achieved 83 percent accuracy on the 10k reads dataset test partition. It seems to plateau there, achieving similar results for the last 8 epochs, and I suspect that before adding more data, which I have, I could make some model-architecture changes that would improve this. PacBio's primrose achieve's 85 percent accuracy, but they don't specify what part of the data was test/train. A group in china was able to get to 0.90 test set accuracy. So for a first attempt, I'm not too dissapointed (assuming I haven't polluted my data in some way), but it would be nice to see if we can improve past 0.85 and then past 0.90.\n",
        "\n",
        "## Future\n",
        "### Contrastive pretraining\n",
        "Train a JEPA with my groups abundant pacbio data. Focus on learning the associations between nucletides and kinetics. Take the encoder, add a classification head, and use it to classify methylation.\n",
        "### Transformers\n",
        "My intution is that a transformer encoder would be much better for the nucleotide section than a CNN. So for future implementations it would be nice to use this for the section of the model that processes the nucleotides.\n",
        "### JAX\n",
        "Yep. I still want to pursue jax. Maybe I'll outgrow it, but after writing this first implementation in pytorch, I still enjoy jax more"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ideas\n",
        "## Test the independent efficacy of kinetics and nucleotides as features\n",
        "Premise: What if one of the nucleotides/kinetics data streams is dominating the prediction? The model could be learning just that some nucleotide contexts occur for methylation, and some don't.\n",
        "\n",
        "Test: Make a nucleotide only and a kinetics only classifier to sanity test whether one is contributing all the predictive information.\n",
        "\n",
        "Result:\n",
        "\n",
        "\n",
        "## Treat nucleotides and kinetics seperately\n",
        "Make a new kinetics+nucleotides model that has seperate towers for the two datatypes. Guessing that architectural choices probably don't generalize between the two. A pretrained transformer would probably be the best for the nucleotides, but for now I'd like to try with just the convolutional type since that was effective for primrose. The next step might be a transformer based JEPA model for pretraining that I could use for downstream methylation detection.\n",
        "\n",
        "## How much context do we need?\n",
        "I chose 32 since that seemed like it woud definitely be large enough (based on the eda plots below). But smaller would make training faster, and carry less risk of running into multiple CG sites per sample. Could be nice to test different context sizes and compare performance."
      ],
      "metadata": {
        "id": "cGO4qX2HhN4M"
      },
      "id": "cGO4qX2HhN4M"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "EcBYtIte_Bae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcBYtIte_Bae",
        "outputId": "6c1da9aa-7893-4d2e-8b1d-de6075d06a1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions\n",
        "1. Do we need to normalize categorical (nucleotide) data? Right now I normalized the kinetics features, but not the one-hot encodings. To me, this was the intuitive obvious solution, but a prof in my deparment keeps bugging me with \"how do you know that the nucleotides are not contributing all the signal information?? how are you choosing to normalize those??\" And I keep thinking... I don't want to normalize one-hot encodings. I mean, I could use label smoothing, but that doesn't seem like the same thing.\n",
        "\n",
        "2. How can we change the architecture so that the model can learn associations between nucleotide contexts and their kinetic signatures? Based on the fact that the kinetics-only model performs almost as well as the kinetics+nucleotides model, I think that the nucleotides are being under-utilized. Simply looking at the kinetics might allow the model to predict methylation to limited accuracy, but as we can see from the EDA plots, CG has as particular kinetic signature distinct from the average surroundings even when it's unmethylated.\n",
        "\n",
        "3. How much risk is there in the fact that sometimes we get two CG instances in the same sample? My hunch is that it would make our test set prediction optimistic, since there is a greater methylation signal (in reality I don't think adjacent CG sites have P(both methylated)=1). On the otherhand, when we move to contrastive pretraining, I suspect that a larger context window will be really beneficial, so I think this is something worth thinking about.\n",
        "\n",
        "4. There's a text box down by training explaining that I needed to switch to a larger batch size to get good epoch training times. But the question is, how do we balance large batch sizes with generalizability? Is this dependent on the optimizer? Or do we just test things and see what works? I would guess the last option is most common, but there must be limits since I was previously told to \"always use a batch size less than 128.\"\n",
        "\n",
        "5. Should we expect that a pretrained contrastive learning model will outperform this, when it is used in downstream finetuning? For me it makes sense that it would help, but I'd be curious to know what your intuition is."
      ],
      "metadata": {
        "id": "-YLlVUows_LB"
      },
      "id": "-YLlVUows_LB"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "Y8Dqzqp3_ImZ",
      "metadata": {
        "id": "Y8Dqzqp3_ImZ"
      },
      "outputs": [],
      "source": [
        "!cp /content/gdrive/MyDrive/methylation/train_cg_32_10000.parquet /content/\n",
        "!cp /content/gdrive/MyDrive/methylation/test_cg_32_10000.parquet /content/\n",
        "\n",
        "\n",
        "\n",
        "train_parquet = '/content/train_cg_32_10000.parquet'\n",
        "test_parquet = '/content/test_cg_32_10000.parquet'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "plip92y7AL-r",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plip92y7AL-r",
        "outputId": "69278227-7174-4498-f187-4bf80b5d6f51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (1.21.0)\n",
            "Requirement already satisfied: vegafusion>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from vegafusion[embed]>=1.5.0) (2.0.2)\n",
            "Requirement already satisfied: vl-convert-python in /usr/local/lib/python3.11/dist-packages (1.8.0)\n",
            "Requirement already satisfied: arro3-core in /usr/local/lib/python3.11/dist-packages (from vegafusion>=1.5.0->vegafusion[embed]>=1.5.0) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from vegafusion>=1.5.0->vegafusion[embed]>=1.5.0) (24.2)\n",
            "Requirement already satisfied: narwhals>=1.13 in /usr/local/lib/python3.11/dist-packages (from vegafusion>=1.5.0->vegafusion[embed]>=1.5.0) (1.44.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from arro3-core->vegafusion>=1.5.0->vegafusion[embed]>=1.5.0) (4.14.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install polars \"vegafusion[embed]>=1.5.0\" vl-convert-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "70734137",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70734137",
        "outputId": "67b39ab3-274f-44f5-cb7e-310a0d7891d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import polars as pl\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import altair as alt\n",
        "alt.data_transformers.enable(\"vegafusion\")\n",
        "from typing import Dict, List, Any, Optional\n",
        "from operator import itemgetter\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "pl.Config(fmt_str_lengths=50)\n",
        "\n",
        "device = torch.device(\n",
        "    \"mps\" if torch.backends.mps.is_available() # this actually works pretty well locally\n",
        "    else \"cuda\" if torch.cuda.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3_FFpKmjTX1m",
      "metadata": {
        "id": "3_FFpKmjTX1m"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Glimpse of the dataset"
      ],
      "metadata": {
        "id": "kZOcRH8pgF-n"
      },
      "id": "kZOcRH8pgF-n"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c4636c8e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "c4636c8e",
        "outputId": "7fe1cff5-5306-452b-9dd5-704fac419d09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (10, 8)\n",
              "┌─────────────┬────────┬─────────────┬─────────────┬─────────────┬────────────┬────────────┬───────┐\n",
              "│ read_name   ┆ cg_pos ┆ seq         ┆ fi          ┆ fp          ┆ ri         ┆ rp         ┆ label │\n",
              "│ ---         ┆ ---    ┆ ---         ┆ ---         ┆ ---         ┆ ---        ┆ ---        ┆ ---   │\n",
              "│ str         ┆ i64    ┆ str         ┆ list[i64]   ┆ list[i64]   ┆ list[i64]  ┆ list[i64]  ┆ i32   │\n",
              "╞═════════════╪════════╪═════════════╪═════════════╪═════════════╪════════════╪════════════╪═══════╡\n",
              "│ m64168_2008 ┆ 10282  ┆ AGATCTATTAC ┆ [52, 29, …  ┆ [19, 10, …  ┆ [62, 14, … ┆ [29, 25, … ┆ 1     │\n",
              "│ 23_191315/1 ┆        ┆ ACAACGTGGTG ┆ 21]         ┆ 14]         ┆ 12]        ┆ 13]        ┆       │\n",
              "│ 837517/ccs  ┆        ┆ ACCATAGCTA  ┆             ┆             ┆            ┆            ┆       │\n",
              "│ m64168_2008 ┆ 5955   ┆ GAAGGGGCTGA ┆ [19, 60, …  ┆ [12, 49, …  ┆ [31, 52, … ┆ [12, 17, … ┆ 0     │\n",
              "│ 20_000733/2 ┆        ┆ TGCCCGGCCTC ┆ 39]         ┆ 24]         ┆ 28]        ┆ 54]        ┆       │\n",
              "│ 63719/ccs   ┆        ┆ AGAGGTTAAG  ┆             ┆             ┆            ┆            ┆       │\n",
              "│ m64168_2008 ┆ 2321   ┆ GACGGGGCAGC ┆ [23, 59, …  ┆ [12, 25, …  ┆ [35, 48, … ┆ [18, 11, … ┆ 1     │\n",
              "│ 23_191315/2 ┆        ┆ TGGCCGGGCGG ┆ 69]         ┆ 9]          ┆ 68]        ┆ 28]        ┆       │\n",
              "│ 63868/ccs   ┆        ┆ GGGGGCTGAC  ┆             ┆             ┆            ┆            ┆       │\n",
              "│ m64168_2008 ┆ 7697   ┆ TGGAATGCAAT ┆ [16, 11, …  ┆ [16, 33, …  ┆ [22, 18, … ┆ [37, 12, … ┆ 1     │\n",
              "│ 23_191315/1 ┆        ┆ GGAACGGAATG ┆ 21]         ┆ 33]         ┆ 12]        ┆ 11]        ┆       │\n",
              "│ 442515/ccs  ┆        ┆ GAGTGGGATG  ┆             ┆             ┆            ┆            ┆       │\n",
              "│ m64168_2008 ┆ 7803   ┆ GATGTACTCCA ┆ [21, 21, …  ┆ [44, 21, …  ┆ [17, 17, … ┆ [11, 26, … ┆ 1     │\n",
              "│ 23_191315/1 ┆        ┆ CTTTCGAGCCT ┆ 22]         ┆ 13]         ┆ 21]        ┆ 41]        ┆       │\n",
              "│ 638483/ccs  ┆        ┆ GATTCAGAAA  ┆             ┆             ┆            ┆            ┆       │\n",
              "│ m64168_2008 ┆ 7290   ┆ GCCTGGGCGAC ┆ [8, 11, …   ┆ [11, 19, …  ┆ [16, 28, … ┆ [40, 36, … ┆ 0     │\n",
              "│ 20_000733/7 ┆        ┆ AGAGCGAGACT ┆ 24]         ┆ 23]         ┆ 60]        ┆ 33]        ┆       │\n",
              "│ 42/ccs      ┆        ┆ CCATCTCAAA  ┆             ┆             ┆            ┆            ┆       │\n",
              "│ m64168_2008 ┆ 7671   ┆ TGGCCTTAAGT ┆ [24, 33, …  ┆ [15, 17, …  ┆ [29, 23, … ┆ [23, 22, … ┆ 0     │\n",
              "│ 20_000733/3 ┆        ┆ GATCCGCCCAC ┆ 141]        ┆ 41]         ┆ 27]        ┆ 15]        ┆       │\n",
              "│ 27687/ccs   ┆        ┆ CTTGGCCTCC  ┆             ┆             ┆            ┆            ┆       │\n",
              "│ m64168_2008 ┆ 4461   ┆ GAAAACTGAGT ┆ [16, 11, …  ┆ [15, 16, …  ┆ [16, 23, … ┆ [23, 9, …  ┆ 0     │\n",
              "│ 20_000733/1 ┆        ┆ CCCCCGTGAGG ┆ 17]         ┆ 17]         ┆ 14]        ┆ 38]        ┆       │\n",
              "│ 32160/ccs   ┆        ┆ ATCTTGTTTT  ┆             ┆             ┆            ┆            ┆       │\n",
              "│ m64168_2008 ┆ 6638   ┆ GGAATAATTCC ┆ [6, 12, …   ┆ [27, 10, …  ┆ [17, 22, … ┆ [27, 10, … ┆ 1     │\n",
              "│ 23_191315/1 ┆        ┆ TTTCCGTCCTC ┆ 10]         ┆ 9]          ┆ 17]        ┆ 13]        ┆       │\n",
              "│ 444273/ccs  ┆        ┆ TCGGGAACAG  ┆             ┆             ┆            ┆            ┆       │\n",
              "│ m64168_2008 ┆ 5944   ┆ CTTAAGAGAAA ┆ [29, 37, …  ┆ [19, 9, …   ┆ [11, 44, … ┆ [21, 67, … ┆ 1     │\n",
              "│ 23_191315/2 ┆        ┆ CAAACGGCCTC ┆ 18]         ┆ 10]         ┆ 27]        ┆ 20]        ┆       │\n",
              "│ 64947/ccs   ┆        ┆ AGGAAGGGCA  ┆             ┆             ┆            ┆            ┆       │\n",
              "└─────────────┴────────┴─────────────┴─────────────┴─────────────┴────────────┴────────────┴───────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (10, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>read_name</th><th>cg_pos</th><th>seq</th><th>fi</th><th>fp</th><th>ri</th><th>rp</th><th>label</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>list[i64]</td><td>list[i64]</td><td>list[i64]</td><td>list[i64]</td><td>i32</td></tr></thead><tbody><tr><td>&quot;m64168_200823_191315/1837517/ccs&quot;</td><td>10282</td><td>&quot;AGATCTATTACACAACGTGGTGACCATAGCTA&quot;</td><td>[52, 29, … 21]</td><td>[19, 10, … 14]</td><td>[62, 14, … 12]</td><td>[29, 25, … 13]</td><td>1</td></tr><tr><td>&quot;m64168_200820_000733/263719/ccs&quot;</td><td>5955</td><td>&quot;GAAGGGGCTGATGCCCGGCCTCAGAGGTTAAG&quot;</td><td>[19, 60, … 39]</td><td>[12, 49, … 24]</td><td>[31, 52, … 28]</td><td>[12, 17, … 54]</td><td>0</td></tr><tr><td>&quot;m64168_200823_191315/263868/ccs&quot;</td><td>2321</td><td>&quot;GACGGGGCAGCTGGCCGGGCGGGGGGGCTGAC&quot;</td><td>[23, 59, … 69]</td><td>[12, 25, … 9]</td><td>[35, 48, … 68]</td><td>[18, 11, … 28]</td><td>1</td></tr><tr><td>&quot;m64168_200823_191315/1442515/ccs&quot;</td><td>7697</td><td>&quot;TGGAATGCAATGGAACGGAATGGAGTGGGATG&quot;</td><td>[16, 11, … 21]</td><td>[16, 33, … 33]</td><td>[22, 18, … 12]</td><td>[37, 12, … 11]</td><td>1</td></tr><tr><td>&quot;m64168_200823_191315/1638483/ccs&quot;</td><td>7803</td><td>&quot;GATGTACTCCACTTTCGAGCCTGATTCAGAAA&quot;</td><td>[21, 21, … 22]</td><td>[44, 21, … 13]</td><td>[17, 17, … 21]</td><td>[11, 26, … 41]</td><td>1</td></tr><tr><td>&quot;m64168_200820_000733/742/ccs&quot;</td><td>7290</td><td>&quot;GCCTGGGCGACAGAGCGAGACTCCATCTCAAA&quot;</td><td>[8, 11, … 24]</td><td>[11, 19, … 23]</td><td>[16, 28, … 60]</td><td>[40, 36, … 33]</td><td>0</td></tr><tr><td>&quot;m64168_200820_000733/327687/ccs&quot;</td><td>7671</td><td>&quot;TGGCCTTAAGTGATCCGCCCACCTTGGCCTCC&quot;</td><td>[24, 33, … 141]</td><td>[15, 17, … 41]</td><td>[29, 23, … 27]</td><td>[23, 22, … 15]</td><td>0</td></tr><tr><td>&quot;m64168_200820_000733/132160/ccs&quot;</td><td>4461</td><td>&quot;GAAAACTGAGTCCCCCGTGAGGATCTTGTTTT&quot;</td><td>[16, 11, … 17]</td><td>[15, 16, … 17]</td><td>[16, 23, … 14]</td><td>[23, 9, … 38]</td><td>0</td></tr><tr><td>&quot;m64168_200823_191315/1444273/ccs&quot;</td><td>6638</td><td>&quot;GGAATAATTCCTTTCCGTCCTCTCGGGAACAG&quot;</td><td>[6, 12, … 10]</td><td>[27, 10, … 9]</td><td>[17, 22, … 17]</td><td>[27, 10, … 13]</td><td>1</td></tr><tr><td>&quot;m64168_200823_191315/264947/ccs&quot;</td><td>5944</td><td>&quot;CTTAAGAGAAACAAACGGCCTCAGGAAGGGCA&quot;</td><td>[29, 37, … 18]</td><td>[19, 9, … 10]</td><td>[11, 44, … 27]</td><td>[21, 67, … 20]</td><td>1</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_df = pl.read_parquet(train_parquet,  schema = {'read_name': pl.String,\n",
        "                                                     'cg_pos': pl.Int64,\n",
        "                                                     'seq': pl.String,\n",
        "                                                     'fi': pl.List(pl.Int64),\n",
        "                                                     'fp': pl.List(pl.Int64),\n",
        "                                                     'ri': pl.List(pl.Int64),\n",
        "                                                     'rp': pl.List(pl.Int64),\n",
        "                                                     'label': pl.Int32\n",
        "                                                     }\n",
        "                           )\n",
        "train_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GNMlhF88WHbs",
      "metadata": {
        "id": "GNMlhF88WHbs"
      },
      "source": [
        "## Mean IPD at Context Indices\n",
        "The chart below shows that at least on average, we should be able to tell the difference between methylated and unmethylted CpG sites. The chart averages IPD at each index across all of the training samples independantly for the forward and reverse strands (indices 15 and 16 are the CpG site)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "G8hj1Q-MTYqJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "id": "G8hj1Q-MTYqJ",
        "outputId": "ba916282-d7cd-405c-aeda-d78004e73cb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "  #altair-viz-bf2b5117acf644b78f0a25ab93293905.vega-embed {\n",
              "    width: 100%;\n",
              "    display: flex;\n",
              "  }\n",
              "\n",
              "  #altair-viz-bf2b5117acf644b78f0a25ab93293905.vega-embed details,\n",
              "  #altair-viz-bf2b5117acf644b78f0a25ab93293905.vega-embed details summary {\n",
              "    position: relative;\n",
              "  }\n",
              "</style>\n",
              "<div id=\"altair-viz-bf2b5117acf644b78f0a25ab93293905\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-bf2b5117acf644b78f0a25ab93293905\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-bf2b5117acf644b78f0a25ab93293905\");\n",
              "    }\n",
              "\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function maybeLoadScript(lib, version) {\n",
              "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
              "      return (VEGA_DEBUG[key] == version) ?\n",
              "        Promise.resolve(paths[lib]) :\n",
              "        new Promise(function(resolve, reject) {\n",
              "          var s = document.createElement('script');\n",
              "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "          s.async = true;\n",
              "          s.onload = () => {\n",
              "            VEGA_DEBUG[key] = version;\n",
              "            return resolve(paths[lib]);\n",
              "          };\n",
              "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "          s.src = paths[lib];\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      let deps = [\"vega-embed\"];\n",
              "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else {\n",
              "      maybeLoadScript(\"vega\", \"5\")\n",
              "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
              "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"$schema\": \"https://vega.github.io/schema/vega/v5.json\", \"data\": [{\"name\": \"source_0\", \"values\": [{\"index\": 22, \"strand\": \"rev\", \"ipd\": 33.17586979081326}, {\"index\": 17, \"strand\": \"fwd\", \"ipd\": 29.420446007206618}, {\"index\": 1, \"strand\": \"fwd\", \"ipd\": 30.33061719756788}, {\"index\": 16, \"strand\": \"fwd\", \"ipd\": 30.56266080926084}, {\"index\": 23, \"strand\": \"fwd\", \"ipd\": 28.011006254493065}, {\"index\": 5, \"strand\": \"rev\", \"ipd\": 30.351425159388455}, {\"index\": 9, \"strand\": \"fwd\", \"ipd\": 30.392734041595258}, {\"index\": 31, \"strand\": \"fwd\", \"ipd\": 30.671208813270095}, {\"index\": 11, \"strand\": \"rev\", \"ipd\": 30.406868280700824}, {\"index\": 21, \"strand\": \"fwd\", \"ipd\": 28.178745351938865}, {\"index\": 9, \"strand\": \"rev\", \"ipd\": 30.302790091418636}, {\"index\": 0, \"strand\": \"fwd\", \"ipd\": 30.368198773900886}, {\"index\": 2, \"strand\": \"fwd\", \"ipd\": 30.04036413933186}, {\"index\": 28, \"strand\": \"rev\", \"ipd\": 30.244357744603526}, {\"index\": 3, \"strand\": \"fwd\", \"ipd\": 30.34698929635846}, {\"index\": 7, \"strand\": \"fwd\", \"ipd\": 30.44656962385948}, {\"index\": 8, \"strand\": \"rev\", \"ipd\": 30.190650588323862}, {\"index\": 10, \"strand\": \"rev\", \"ipd\": 30.689234212091822}, {\"index\": 6, \"strand\": \"rev\", \"ipd\": 30.84939174796622}, {\"index\": 24, \"strand\": \"fwd\", \"ipd\": 30.22426424458212}, {\"index\": 19, \"strand\": \"fwd\", \"ipd\": 26.954975621205346}, {\"index\": 4, \"strand\": \"rev\", \"ipd\": 30.07989572400518}, {\"index\": 26, \"strand\": \"rev\", \"ipd\": 29.67409470752089}, {\"index\": 17, \"strand\": \"rev\", \"ipd\": 29.37914745812501}, {\"index\": 25, \"strand\": \"rev\", \"ipd\": 30.753615486697576}, {\"index\": 29, \"strand\": \"fwd\", \"ipd\": 29.96050974782746}, {\"index\": 29, \"strand\": \"rev\", \"ipd\": 29.72837756648997}, {\"index\": 7, \"strand\": \"rev\", \"ipd\": 30.28521049314102}, {\"index\": 19, \"strand\": \"rev\", \"ipd\": 27.12961724628118}, {\"index\": 4, \"strand\": \"fwd\", \"ipd\": 30.209734394397675}, {\"index\": 14, \"strand\": \"rev\", \"ipd\": 34.378573231596334}, {\"index\": 24, \"strand\": \"rev\", \"ipd\": 30.003251982114836}, {\"index\": 18, \"strand\": \"rev\", \"ipd\": 29.067720350204375}, {\"index\": 20, \"strand\": \"fwd\", \"ipd\": 30.516923444827754}, {\"index\": 12, \"strand\": \"rev\", \"ipd\": 31.066421328751332}, {\"index\": 18, \"strand\": \"fwd\", \"ipd\": 29.212037205155344}, {\"index\": 31, \"strand\": \"rev\", \"ipd\": 30.33751677287643}, {\"index\": 2, \"strand\": \"rev\", \"ipd\": 29.94563299986862}, {\"index\": 28, \"strand\": \"fwd\", \"ipd\": 30.54293339710348}, {\"index\": 27, \"strand\": \"rev\", \"ipd\": 30.064282371836033}, {\"index\": 3, \"strand\": \"rev\", \"ipd\": 30.18317235800441}, {\"index\": 16, \"strand\": \"rev\", \"ipd\": 29.704205434338157}, {\"index\": 1, \"strand\": \"rev\", \"ipd\": 30.193968997672094}, {\"index\": 21, \"strand\": \"rev\", \"ipd\": 28.266914956903488}, {\"index\": 0, \"strand\": \"rev\", \"ipd\": 30.207000544703313}, {\"index\": 6, \"strand\": \"fwd\", \"ipd\": 31.03215225712358}, {\"index\": 5, \"strand\": \"fwd\", \"ipd\": 30.460007115094776}, {\"index\": 10, \"strand\": \"fwd\", \"ipd\": 30.849713551007998}, {\"index\": 25, \"strand\": \"fwd\", \"ipd\": 30.965165558808028}, {\"index\": 30, \"strand\": \"rev\", \"ipd\": 30.413570050469936}, {\"index\": 13, \"strand\": \"fwd\", \"ipd\": 32.68761191143626}, {\"index\": 27, \"strand\": \"fwd\", \"ipd\": 30.269879087673615}, {\"index\": 14, \"strand\": \"fwd\", \"ipd\": 36.02927226751576}, {\"index\": 11, \"strand\": \"fwd\", \"ipd\": 30.59299886483239}, {\"index\": 20, \"strand\": \"rev\", \"ipd\": 30.049342148965284}, {\"index\": 15, \"strand\": \"fwd\", \"ipd\": 31.77238339437258}, {\"index\": 22, \"strand\": \"fwd\", \"ipd\": 34.082512957000915}, {\"index\": 15, \"strand\": \"rev\", \"ipd\": 31.110226398773015}, {\"index\": 8, \"strand\": \"fwd\", \"ipd\": 30.27027617491324}, {\"index\": 26, \"strand\": \"fwd\", \"ipd\": 29.934877692701715}, {\"index\": 23, \"strand\": \"rev\", \"ipd\": 28.145849109801265}, {\"index\": 13, \"strand\": \"rev\", \"ipd\": 31.741327924680373}, {\"index\": 30, \"strand\": \"fwd\", \"ipd\": 30.739312965267413}, {\"index\": 12, \"strand\": \"fwd\", \"ipd\": 31.32374419315268}]}, {\"name\": \"source_1\", \"values\": [{\"index\": 17, \"strand\": \"rev\", \"ipd\": 29.81608079437469}, {\"index\": 25, \"strand\": \"rev\", \"ipd\": 31.115440796948132}, {\"index\": 13, \"strand\": \"rev\", \"ipd\": 30.94111497289844}, {\"index\": 23, \"strand\": \"rev\", \"ipd\": 26.8782367244765}, {\"index\": 19, \"strand\": \"fwd\", \"ipd\": 26.879745697161464}, {\"index\": 27, \"strand\": \"fwd\", \"ipd\": 29.48059464051504}, {\"index\": 20, \"strand\": \"fwd\", \"ipd\": 30.99482679713237}, {\"index\": 30, \"strand\": \"fwd\", \"ipd\": 29.941123745995448}, {\"index\": 27, \"strand\": \"rev\", \"ipd\": 29.01661039699726}, {\"index\": 1, \"strand\": \"rev\", \"ipd\": 29.05647242542502}, {\"index\": 16, \"strand\": \"rev\", \"ipd\": 34.196744011264656}, {\"index\": 28, \"strand\": \"fwd\", \"ipd\": 29.841291750803105}, {\"index\": 21, \"strand\": \"rev\", \"ipd\": 27.08853370843197}, {\"index\": 12, \"strand\": \"fwd\", \"ipd\": 30.16645928040134}, {\"index\": 11, \"strand\": \"fwd\", \"ipd\": 29.512462915387864}, {\"index\": 14, \"strand\": \"fwd\", \"ipd\": 37.96189259097336}, {\"index\": 26, \"strand\": \"fwd\", \"ipd\": 29.02227635548004}, {\"index\": 12, \"strand\": \"rev\", \"ipd\": 29.745214641129156}, {\"index\": 20, \"strand\": \"rev\", \"ipd\": 30.060885293218835}, {\"index\": 3, \"strand\": \"fwd\", \"ipd\": 29.361673848421354}, {\"index\": 3, \"strand\": \"rev\", \"ipd\": 28.978084803680023}, {\"index\": 10, \"strand\": \"fwd\", \"ipd\": 30.017516950354505}, {\"index\": 5, \"strand\": \"rev\", \"ipd\": 29.033384558471962}, {\"index\": 8, \"strand\": \"rev\", \"ipd\": 29.08952360621077}, {\"index\": 16, \"strand\": \"fwd\", \"ipd\": 36.16591242402132}, {\"index\": 31, \"strand\": \"rev\", \"ipd\": 29.062863626593597}, {\"index\": 22, \"strand\": \"fwd\", \"ipd\": 38.57072359041919}, {\"index\": 23, \"strand\": \"fwd\", \"ipd\": 26.95472643290262}, {\"index\": 19, \"strand\": \"rev\", \"ipd\": 26.575618978548317}, {\"index\": 17, \"strand\": \"fwd\", \"ipd\": 30.112199137604563}, {\"index\": 1, \"strand\": \"fwd\", \"ipd\": 29.36981382025971}, {\"index\": 9, \"strand\": \"fwd\", \"ipd\": 29.375899425215927}, {\"index\": 4, \"strand\": \"fwd\", \"ipd\": 29.175682729719888}, {\"index\": 13, \"strand\": \"fwd\", \"ipd\": 32.10907591507057}, {\"index\": 28, \"strand\": \"rev\", \"ipd\": 29.36447539073181}, {\"index\": 29, \"strand\": \"rev\", \"ipd\": 28.688686652756434}, {\"index\": 15, \"strand\": \"rev\", \"ipd\": 30.353760514922307}, {\"index\": 5, \"strand\": \"fwd\", \"ipd\": 29.314977577426237}, {\"index\": 7, \"strand\": \"rev\", \"ipd\": 29.129337382604994}, {\"index\": 22, \"strand\": \"rev\", \"ipd\": 36.80435262586104}, {\"index\": 30, \"strand\": \"rev\", \"ipd\": 29.430618693422662}, {\"index\": 2, \"strand\": \"fwd\", \"ipd\": 29.21606968178515}, {\"index\": 18, \"strand\": \"rev\", \"ipd\": 38.287764892697716}, {\"index\": 4, \"strand\": \"rev\", \"ipd\": 28.909664882316214}, {\"index\": 10, \"strand\": \"rev\", \"ipd\": 29.690043558426634}, {\"index\": 6, \"strand\": \"fwd\", \"ipd\": 30.319557134063157}, {\"index\": 7, \"strand\": \"fwd\", \"ipd\": 29.45402824059926}, {\"index\": 21, \"strand\": \"fwd\", \"ipd\": 27.30697651295713}, {\"index\": 14, \"strand\": \"rev\", \"ipd\": 35.573900913718056}, {\"index\": 25, \"strand\": \"fwd\", \"ipd\": 31.71534078364227}, {\"index\": 0, \"strand\": \"fwd\", \"ipd\": 29.405046577834185}, {\"index\": 29, \"strand\": \"fwd\", \"ipd\": 29.128394274676893}, {\"index\": 24, \"strand\": \"rev\", \"ipd\": 28.680078782411112}, {\"index\": 18, \"strand\": \"fwd\", \"ipd\": 40.51491207163526}, {\"index\": 15, \"strand\": \"fwd\", \"ipd\": 31.314113427371186}, {\"index\": 8, \"strand\": \"fwd\", \"ipd\": 29.343593957675655}, {\"index\": 11, \"strand\": \"rev\", \"ipd\": 29.136285675433427}, {\"index\": 24, \"strand\": \"fwd\", \"ipd\": 29.055412342870177}, {\"index\": 26, \"strand\": \"rev\", \"ipd\": 28.574583753101656}, {\"index\": 6, \"strand\": \"rev\", \"ipd\": 29.876449937053028}, {\"index\": 0, \"strand\": \"rev\", \"ipd\": 29.10583279354417}, {\"index\": 31, \"strand\": \"fwd\", \"ipd\": 29.54996936726962}, {\"index\": 2, \"strand\": \"rev\", \"ipd\": 28.891557210096664}, {\"index\": 9, \"strand\": \"rev\", \"ipd\": 29.16041023001598}]}, {\"name\": \"source_0_color_domain_strand_0\", \"values\": [{\"strand\": \"rev\"}, {\"strand\": \"fwd\"}]}, {\"name\": \"source_1_color_domain_strand_1\", \"values\": [{\"strand\": \"rev\"}, {\"strand\": \"fwd\"}]}], \"signals\": [{\"name\": \"childWidth\", \"value\": 800}], \"marks\": [{\"type\": \"group\", \"name\": \"concat_0_group\", \"encode\": {\"update\": {\"width\": {\"signal\": \"childWidth\"}, \"height\": {\"signal\": \"height\"}}}, \"marks\": [{\"type\": \"group\", \"name\": \"concat_0_pathgroup\", \"from\": {\"facet\": {\"data\": \"source_0\", \"name\": \"faceted_path_concat_0_main\", \"groupby\": [\"strand\"]}}, \"encode\": {\"update\": {\"width\": {\"field\": {\"signal\": null, \"datum\": null, \"group\": \"width\", \"parent\": null}}, \"height\": {\"field\": {\"signal\": null, \"datum\": null, \"group\": \"height\", \"parent\": null}}}}, \"marks\": [{\"type\": \"line\", \"name\": \"concat_0_marks\", \"from\": {\"data\": \"faceted_path_concat_0_main\"}, \"sort\": {\"field\": \"x\"}, \"encode\": {\"update\": {\"stroke\": {\"field\": \"strand\", \"scale\": \"color\"}, \"y\": {\"field\": \"ipd\", \"scale\": \"concat_0_y\"}, \"defined\": {\"signal\": \"isValid(datum[\\\"index\\\"]) && isFinite(+datum[\\\"index\\\"]) && isValid(datum[\\\"ipd\\\"]) && isFinite(+datum[\\\"ipd\\\"])\"}, \"x\": {\"field\": \"index\", \"scale\": \"concat_0_x\"}}}, \"style\": [\"line\"]}]}], \"axes\": [{\"scale\": \"concat_0_x\", \"maxExtent\": 0, \"grid\": true, \"aria\": false, \"tickCount\": {\"signal\": \"ceil(childWidth/40)\"}, \"orient\": \"bottom\", \"ticks\": false, \"labels\": false, \"zindex\": 0, \"gridScale\": \"concat_0_y\", \"domain\": false, \"minExtent\": 0}, {\"scale\": \"concat_0_y\", \"orient\": \"left\", \"aria\": false, \"domain\": false, \"grid\": true, \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"gridScale\": \"concat_0_x\", \"minExtent\": 0, \"maxExtent\": 0, \"labels\": false, \"ticks\": false, \"zindex\": 0}, {\"scale\": \"concat_0_x\", \"tickCount\": {\"signal\": \"ceil(childWidth/40)\"}, \"labelFlush\": true, \"grid\": false, \"labelOverlap\": true, \"zindex\": 0, \"title\": \"index\", \"orient\": \"bottom\"}, {\"scale\": \"concat_0_y\", \"grid\": false, \"orient\": \"left\", \"labelOverlap\": true, \"title\": \"mean IPD\", \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"zindex\": 0}], \"title\": {\"text\": \"Mean Unmethylated IPD Across CG Context\", \"frame\": \"group\"}, \"style\": \"cell\"}, {\"type\": \"group\", \"name\": \"concat_1_group\", \"encode\": {\"update\": {\"width\": {\"signal\": \"childWidth\"}, \"height\": {\"signal\": \"height\"}}}, \"marks\": [{\"type\": \"group\", \"name\": \"concat_1_pathgroup\", \"from\": {\"facet\": {\"data\": \"source_1\", \"name\": \"faceted_path_concat_1_main\", \"groupby\": [\"strand\"]}}, \"encode\": {\"update\": {\"width\": {\"field\": {\"signal\": null, \"datum\": null, \"group\": \"width\", \"parent\": null}}, \"height\": {\"field\": {\"signal\": null, \"datum\": null, \"group\": \"height\", \"parent\": null}}}}, \"marks\": [{\"type\": \"line\", \"name\": \"concat_1_marks\", \"from\": {\"data\": \"faceted_path_concat_1_main\"}, \"sort\": {\"field\": \"x\"}, \"encode\": {\"update\": {\"stroke\": {\"field\": \"strand\", \"scale\": \"color\"}, \"x\": {\"field\": \"index\", \"scale\": \"concat_1_x\"}, \"y\": {\"field\": \"ipd\", \"scale\": \"concat_1_y\"}, \"defined\": {\"signal\": \"isValid(datum[\\\"index\\\"]) && isFinite(+datum[\\\"index\\\"]) && isValid(datum[\\\"ipd\\\"]) && isFinite(+datum[\\\"ipd\\\"])\"}}}, \"style\": [\"line\"]}]}], \"axes\": [{\"scale\": \"concat_1_x\", \"tickCount\": {\"signal\": \"ceil(childWidth/40)\"}, \"aria\": false, \"domain\": false, \"labels\": false, \"minExtent\": 0, \"grid\": true, \"ticks\": false, \"zindex\": 0, \"maxExtent\": 0, \"gridScale\": \"concat_1_y\", \"orient\": \"bottom\"}, {\"scale\": \"concat_1_y\", \"maxExtent\": 0, \"grid\": true, \"gridScale\": \"concat_1_x\", \"zindex\": 0, \"ticks\": false, \"minExtent\": 0, \"domain\": false, \"labels\": false, \"orient\": \"left\", \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"aria\": false}, {\"scale\": \"concat_1_x\", \"orient\": \"bottom\", \"tickCount\": {\"signal\": \"ceil(childWidth/40)\"}, \"zindex\": 0, \"labelFlush\": true, \"title\": \"index\", \"labelOverlap\": true, \"grid\": false}, {\"scale\": \"concat_1_y\", \"title\": \"mean IPD\", \"orient\": \"left\", \"labelOverlap\": true, \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"zindex\": 0, \"grid\": false}], \"title\": {\"text\": \"Mean Methylated IPD Across CG Context\", \"frame\": \"group\"}, \"style\": \"cell\"}], \"scales\": [{\"name\": \"color\", \"type\": \"ordinal\", \"domain\": {\"fields\": [{\"data\": \"source_0_color_domain_strand_0\", \"field\": \"strand\"}, {\"data\": \"source_1_color_domain_strand_1\", \"field\": \"strand\"}], \"sort\": true}, \"range\": \"category\"}, {\"name\": \"concat_0_x\", \"type\": \"linear\", \"domain\": [0, 31], \"range\": [0, {\"signal\": \"childWidth\"}], \"zero\": true}, {\"name\": \"concat_0_y\", \"type\": \"linear\", \"domain\": [24, 44], \"range\": [{\"signal\": \"height\"}, 0], \"clamp\": true, \"zero\": false}, {\"name\": \"concat_1_x\", \"type\": \"linear\", \"domain\": [0, 31], \"range\": [0, {\"signal\": \"childWidth\"}], \"zero\": true}, {\"name\": \"concat_1_y\", \"type\": \"linear\", \"domain\": [24, 44], \"range\": [{\"signal\": \"height\"}, 0], \"zero\": false, \"clamp\": true}], \"background\": \"white\", \"padding\": 5, \"legends\": [{\"stroke\": \"color\", \"symbolType\": \"stroke\", \"title\": \"strand\"}], \"height\": 600, \"layout\": {\"padding\": 20, \"bounds\": \"full\", \"align\": \"each\"}}, {\"mode\": \"vega\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.HConcatChart(...)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# df of means for methlated data at each index\n",
        "pos_means = (\n",
        "    pl.read_parquet(train_parquet)\n",
        "    .filter(pl.col('label')==1)\n",
        "    .select(pl.col(\"fi\").alias(\"fwd\"), pl.col(\"ri\").alias(\"rev\"))\n",
        "    .unpivot(on=[\"fwd\", \"rev\"], variable_name=\"strand\", value_name=\"ipd_list\")\n",
        "    .with_columns(index=pl.int_ranges(start=0, end=pl.col(\"ipd_list\").list.len()))\n",
        "    .explode(\"index\", \"ipd_list\")\n",
        "    .rename({\"ipd_list\": \"ipd\"})\n",
        "    .group_by(\"index\", \"strand\").agg(pl.col(\"ipd\").mean())\n",
        ")\n",
        "# df of means for unmethlated data at each index\n",
        "neg_means = (\n",
        "    pl.read_parquet(train_parquet)\n",
        "    .filter(pl.col('label')==0)\n",
        "    .select(pl.col(\"fi\").alias(\"fwd\"), pl.col(\"ri\").alias(\"rev\"))\n",
        "    .unpivot(on=[\"fwd\", \"rev\"], variable_name=\"strand\", value_name=\"ipd_list\")\n",
        "    .with_columns(index=pl.int_ranges(start=0, end=pl.col(\"ipd_list\").list.len()))\n",
        "    .explode(\"index\", \"ipd_list\")\n",
        "    .rename({\"ipd_list\": \"ipd\"})\n",
        "    .group_by(\"index\", \"strand\").agg(pl.col(\"ipd\").mean())\n",
        ")\n",
        "\n",
        "# join on index/strand\n",
        "means = pos_means.join(\n",
        "    neg_means, on=['index', 'strand'], suffix='_neg'\n",
        "    ).with_columns((pl.col('ipd')-pl.col('ipd_neg')).alias('residual'))\n",
        "\n",
        "# make a chart of the difference between pos/neg mean at each index\n",
        "residual_chart = alt.Chart(means).mark_line().encode(\n",
        "    alt.X(\"index:Q\", title=\"Position\", axis=alt.Axis(tickCount=16)),\n",
        "    alt.Y(\"residual:Q\", title=\"IPD Mean Difference\", scale=alt.Scale(domain=(-3, 15), clamp=True)),\n",
        "    alt.Color(\"strand:N\", title=\"Strand\"),\n",
        "    ).properties(\n",
        "    title = \"Mean IPD Residual (Meth-Unmeth) Across CG Context\",\n",
        "    width=800,\n",
        "    height=600\n",
        "    ).configure_axis(\n",
        "    labelFontSize=12,\n",
        "    titleFontSize=14,\n",
        "    grid=True\n",
        "    ).configure_title(\n",
        "    fontSize=16,\n",
        "    anchor='middle'\n",
        "    ).configure_legend(\n",
        "    titleFontSize=12,\n",
        "    labelFontSize=11\n",
        "    )\n",
        "# chart of unmethylated mean at each index\n",
        "neg_chart = alt.Chart(neg_means).mark_line().encode(\n",
        "    alt.X('index:Q',scale=alt.Scale(domain=(0, 31))),\n",
        "    alt.Y('ipd:Q', title = 'mean IPD' ,scale=alt.Scale(domain=(24, 44), clamp=True)),\n",
        "    alt.Color('strand')\n",
        "    ).properties(\n",
        "    title = \"Mean Unmethylated IPD Across CG Context\",\n",
        "    width=800,\n",
        "    height=600\n",
        "    )\n",
        "# chart of methylated mean at each index\n",
        "pos_chart = alt.Chart(pos_means).mark_line().encode(\n",
        "    alt.X('index:Q',scale=alt.Scale(domain=(0, 31))),\n",
        "    alt.Y('ipd:Q', title = 'mean IPD' ,scale=alt.Scale(domain=(24, 44), clamp=True)),\n",
        "    alt.Color('strand')\n",
        "    ).properties(\n",
        "    title = \"Mean Methylated IPD Across CG Context\",\n",
        "    width=800,\n",
        "    height=600\n",
        "    )\n",
        "\n",
        "# display the charts\n",
        "alt.hconcat(neg_chart,pos_chart)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How many CPG sites per sample?\n",
        "Every sample has a CG at the center, but this does not guarantee that there are no CG's in the rest of the sample."
      ],
      "metadata": {
        "id": "ySfdTScMelD3"
      },
      "id": "ySfdTScMelD3"
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_counts= train_df.with_columns(\n",
        "    pl.col(\"seq\").str.count_matches(\"CG\").alias(\"cg_count\")\n",
        ")\n",
        "print(train_df_counts.head())\n",
        "alt.Chart(train_df_counts).mark_bar().encode(\n",
        "    alt.X('cg_count:O'),\n",
        "    alt.Y('count():Q')\n",
        ").properties(\n",
        "    width=700,\n",
        "    height=500,\n",
        "    title=f'Distribution of CG Instances in Training Context Windows ({len(train_df)} samples)'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        },
        "id": "KRXBPLHUejoZ",
        "outputId": "0e1fc3d1-ef76-4579-91a6-ae96d96baefc"
      },
      "id": "KRXBPLHUejoZ",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (5, 9)\n",
            "┌─────────────┬────────┬─────────────┬────────────┬───┬────────────┬────────────┬───────┬──────────┐\n",
            "│ read_name   ┆ cg_pos ┆ seq         ┆ fi         ┆ … ┆ ri         ┆ rp         ┆ label ┆ cg_count │\n",
            "│ ---         ┆ ---    ┆ ---         ┆ ---        ┆   ┆ ---        ┆ ---        ┆ ---   ┆ ---      │\n",
            "│ str         ┆ i64    ┆ str         ┆ list[i64]  ┆   ┆ list[i64]  ┆ list[i64]  ┆ i32   ┆ u32      │\n",
            "╞═════════════╪════════╪═════════════╪════════════╪═══╪════════════╪════════════╪═══════╪══════════╡\n",
            "│ m64168_2008 ┆ 10282  ┆ AGATCTATTAC ┆ [52, 29, … ┆ … ┆ [62, 14, … ┆ [29, 25, … ┆ 1     ┆ 1        │\n",
            "│ 23_191315/1 ┆        ┆ ACAACGTGGTG ┆ 21]        ┆   ┆ 12]        ┆ 13]        ┆       ┆          │\n",
            "│ 837517/ccs  ┆        ┆ ACCATAGCTA  ┆            ┆   ┆            ┆            ┆       ┆          │\n",
            "│ m64168_2008 ┆ 5955   ┆ GAAGGGGCTGA ┆ [19, 60, … ┆ … ┆ [31, 52, … ┆ [12, 17, … ┆ 0     ┆ 1        │\n",
            "│ 20_000733/2 ┆        ┆ TGCCCGGCCTC ┆ 39]        ┆   ┆ 28]        ┆ 54]        ┆       ┆          │\n",
            "│ 63719/ccs   ┆        ┆ AGAGGTTAAG  ┆            ┆   ┆            ┆            ┆       ┆          │\n",
            "│ m64168_2008 ┆ 2321   ┆ GACGGGGCAGC ┆ [23, 59, … ┆ … ┆ [35, 48, … ┆ [18, 11, … ┆ 1     ┆ 3        │\n",
            "│ 23_191315/2 ┆        ┆ TGGCCGGGCGG ┆ 69]        ┆   ┆ 68]        ┆ 28]        ┆       ┆          │\n",
            "│ 63868/ccs   ┆        ┆ GGGGGCTGAC  ┆            ┆   ┆            ┆            ┆       ┆          │\n",
            "│ m64168_2008 ┆ 7697   ┆ TGGAATGCAAT ┆ [16, 11, … ┆ … ┆ [22, 18, … ┆ [37, 12, … ┆ 1     ┆ 1        │\n",
            "│ 23_191315/1 ┆        ┆ GGAACGGAATG ┆ 21]        ┆   ┆ 12]        ┆ 11]        ┆       ┆          │\n",
            "│ 442515/ccs  ┆        ┆ GAGTGGGATG  ┆            ┆   ┆            ┆            ┆       ┆          │\n",
            "│ m64168_2008 ┆ 7803   ┆ GATGTACTCCA ┆ [21, 21, … ┆ … ┆ [17, 17, … ┆ [11, 26, … ┆ 1     ┆ 1        │\n",
            "│ 23_191315/1 ┆        ┆ CTTTCGAGCCT ┆ 22]        ┆   ┆ 21]        ┆ 41]        ┆       ┆          │\n",
            "│ 638483/ccs  ┆        ┆ GATTCAGAAA  ┆            ┆   ┆            ┆            ┆       ┆          │\n",
            "└─────────────┴────────┴─────────────┴────────────┴───┴────────────┴────────────┴───────┴──────────┘\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "  #altair-viz-f3f2fecf5f144a7f9f6fac4f6c1bb522.vega-embed {\n",
              "    width: 100%;\n",
              "    display: flex;\n",
              "  }\n",
              "\n",
              "  #altair-viz-f3f2fecf5f144a7f9f6fac4f6c1bb522.vega-embed details,\n",
              "  #altair-viz-f3f2fecf5f144a7f9f6fac4f6c1bb522.vega-embed details summary {\n",
              "    position: relative;\n",
              "  }\n",
              "</style>\n",
              "<div id=\"altair-viz-f3f2fecf5f144a7f9f6fac4f6c1bb522\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-f3f2fecf5f144a7f9f6fac4f6c1bb522\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-f3f2fecf5f144a7f9f6fac4f6c1bb522\");\n",
              "    }\n",
              "\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function maybeLoadScript(lib, version) {\n",
              "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
              "      return (VEGA_DEBUG[key] == version) ?\n",
              "        Promise.resolve(paths[lib]) :\n",
              "        new Promise(function(resolve, reject) {\n",
              "          var s = document.createElement('script');\n",
              "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "          s.async = true;\n",
              "          s.onload = () => {\n",
              "            VEGA_DEBUG[key] = version;\n",
              "            return resolve(paths[lib]);\n",
              "          };\n",
              "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "          s.src = paths[lib];\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      let deps = [\"vega-embed\"];\n",
              "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else {\n",
              "      maybeLoadScript(\"vega\", \"5\")\n",
              "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
              "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"$schema\": \"https://vega.github.io/schema/vega/v5.json\", \"data\": [{\"name\": \"source_0\", \"values\": [{\"__count\": 840975, \"cg_count\": 1}, {\"__count\": 120403, \"cg_count\": 3}, {\"__count\": 343794, \"cg_count\": 2}, {\"__count\": 4184, \"cg_count\": 6}, {\"__count\": 38196, \"cg_count\": 4}, {\"__count\": 1313, \"cg_count\": 7}, {\"__count\": 11958, \"cg_count\": 5}, {\"__count\": 365, \"cg_count\": 8}, {\"__count\": 100, \"cg_count\": 9}, {\"__count\": 19, \"cg_count\": 11}, {\"__count\": 2, \"cg_count\": 13}, {\"__count\": 30, \"cg_count\": 10}, {\"__count\": 1, \"cg_count\": 14}, {\"__count\": 2, \"cg_count\": 12}]}, {\"name\": \"source_0_x_domain_cg_count\", \"values\": [{\"cg_count\": 1}, {\"cg_count\": 3}, {\"cg_count\": 2}, {\"cg_count\": 6}, {\"cg_count\": 4}, {\"cg_count\": 7}, {\"cg_count\": 5}, {\"cg_count\": 8}, {\"cg_count\": 9}, {\"cg_count\": 11}, {\"cg_count\": 13}, {\"cg_count\": 10}, {\"cg_count\": 14}, {\"cg_count\": 12}]}, {\"name\": \"source_0_y_domain___count\", \"values\": [{\"min\": 1, \"max\": 840975}]}], \"marks\": [{\"type\": \"rect\", \"name\": \"marks\", \"from\": {\"data\": \"source_0\"}, \"encode\": {\"update\": {\"width\": {\"signal\": \"max(0.25, bandwidth('x'))\"}, \"y\": {\"field\": \"__count\", \"scale\": \"y\"}, \"fill\": {\"value\": \"#4c78a8\"}, \"y2\": {\"value\": 0, \"scale\": \"y\"}, \"x\": {\"field\": \"cg_count\", \"scale\": \"x\"}}}, \"style\": [\"bar\"]}], \"scales\": [{\"name\": \"x\", \"type\": \"band\", \"domain\": {\"data\": \"source_0_x_domain_cg_count\", \"field\": \"cg_count\", \"sort\": true}, \"range\": [0, {\"signal\": \"width\"}], \"paddingInner\": 0.1, \"paddingOuter\": 0.05}, {\"name\": \"y\", \"type\": \"linear\", \"domain\": [{\"signal\": \"(data(\\\"source_0_y_domain___count\\\")[0] || {}).min\"}, {\"signal\": \"(data(\\\"source_0_y_domain___count\\\")[0] || {}).max\"}], \"range\": [{\"signal\": \"height\"}, 0], \"zero\": true, \"nice\": true}], \"axes\": [{\"scale\": \"y\", \"aria\": false, \"gridScale\": \"x\", \"domain\": false, \"labels\": false, \"maxExtent\": 0, \"orient\": \"left\", \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"minExtent\": 0, \"grid\": true, \"ticks\": false, \"zindex\": 0}, {\"scale\": \"x\", \"zindex\": 0, \"grid\": false, \"labelAlign\": \"right\", \"labelBaseline\": \"middle\", \"title\": \"cg_count\", \"labelAngle\": 270, \"orient\": \"bottom\"}, {\"scale\": \"y\", \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"zindex\": 0, \"orient\": \"left\", \"title\": \"Count of Records\", \"grid\": false, \"labelOverlap\": true}], \"title\": {\"text\": \"Distribution of CG Instances in Training Context Windows (1361342 samples)\", \"frame\": \"group\"}, \"width\": 700, \"height\": 500, \"padding\": 5, \"style\": \"cell\", \"background\": \"white\"}, {\"mode\": \"vega\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.Chart(...)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8oxRTUocJ_nr",
      "metadata": {
        "id": "8oxRTUocJ_nr"
      },
      "source": [
        "# Normalization\n",
        "Precompute on the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4c2396ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c2396ef",
        "outputId": "34ab5098-9388-4824-bcb9-72e14a7188ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fi': 30.594821621789382, 'fp': 21.945176340699103, 'ri': 30.13117185101172, 'rp': 22.007529335023822} {'fi': 24.25535836619395, 'fp': 11.27049294825807, 'ri': 23.845802361655878, 'rp': 11.310865492241938}\n"
          ]
        }
      ],
      "source": [
        "def compute_normalization_stats(df):\n",
        "    kinetic_features = ['fi', 'fp', 'ri', 'rp']\n",
        "    means = {col: df[col].explode().mean() for col in kinetic_features}\n",
        "    stds = {col: df[col].explode().explode().std() for col in kinetic_features}\n",
        "    return means, stds\n",
        "train_means, train_stds = compute_normalization_stats(train_df)\n",
        "print(train_means, train_stds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "foq4xK12J90_",
      "metadata": {
        "id": "foq4xK12J90_"
      },
      "source": [
        "# Dataset Definition\n",
        "## Notes\n",
        "1. this does not include a transform implementation.\n",
        "2. turning the entire dataset into tensor inside __init__ resultined in a 2x speedup in training (before the tensor initiation was in getitem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e2058e2f",
      "metadata": {
        "id": "e2058e2f"
      },
      "outputs": [],
      "source": [
        "class MethylDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset class for metylation data stored in a parquet file\n",
        "    Reads data using polars and converts samples to pytorch tensors before get_item call\n",
        "    Nucleotide sequence is one-hot encoded\n",
        "    \"\"\"\n",
        "    def __init__(self, data_path: Path,\n",
        "                 means: Optional[Dict[str, float]] = train_means,\n",
        "                 stds: Optional[Dict[str, float]] = train_stds,\n",
        "                 context: int = 32):\n",
        "        '''\n",
        "        Arguments:\n",
        "        data_path: the path for the parquet file that contains either the training or test data (pos and neg)\n",
        "        transform: an optional transform callable on a single sample\n",
        "        '''\n",
        "        self.means = means\n",
        "        self.stds = stds\n",
        "        self.context = 32\n",
        "        self.kinetics_features = ['fi', 'fp', 'ri', 'rp']\n",
        "\n",
        "        # initialize the dataframe, converting kinetic columns in to pl.array\n",
        "        try:\n",
        "             self.df = pl.read_parquet(data_path).with_columns([\n",
        "                 pl.col(\"fi\").list.to_array(self.context),\n",
        "                 pl.col(\"fp\").list.to_array(self.context),\n",
        "                 pl.col(\"ri\").list.to_array(self.context),\n",
        "                 pl.col(\"rp\").list.to_array(self.context),\n",
        "                 ])\n",
        "        # intialize with empty df if loading fails\n",
        "        except:\n",
        "             print(f\"failed to read data given path: {data_path}\")\n",
        "             self.df = pl.DataFrame()\n",
        "\n",
        "        self._dataset_len = len(self.df)\n",
        "        self.vocab = {'A':0, 'T':1, 'C':2, 'G':3}\n",
        "        self.vocab_size = len(self.vocab)\n",
        "        self.kinetic_features = ['fi', 'fp', 'ri', 'rp']\n",
        "        # define the sequence tensor\n",
        "        self.seq_tensor = self._prep_seq_tensor()\n",
        "        # define the kinetics tensor\n",
        "        self.kinetics_tensor = self._prep_kinetics_tensor()\n",
        "        # define the label tensor\n",
        "        self.label_tensor = self._prep_label_tensor()\n",
        "\n",
        "    def _prep_seq_tensor(self):\n",
        "      seq_ints = (\n",
        "          self.df['seq']\n",
        "          .str.split(\"\")\n",
        "          .list.eval(\n",
        "              pl.element().replace_strict(self.vocab)\n",
        "          )\n",
        "          .to_numpy()\n",
        "      )\n",
        "      return torch.tensor(np.stack(seq_ints), dtype=torch.long)\n",
        "\n",
        "    def _prep_kinetics_tensor(self):\n",
        "      kinetics_array = np.stack([self.df[col].to_numpy() for col in self.kinetics_features], axis=1)\n",
        "      return torch.tensor(kinetics_array, dtype=torch.long)\n",
        "\n",
        "    def _prep_label_tensor(self):\n",
        "      label_array = self.df['label'].to_numpy()\n",
        "      return torch.tensor(label_array, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "          return self._dataset_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "         if idx >= len(self):\n",
        "              raise IndexError(\"Index out of range\")\n",
        "         seq, kinetics, label = self.seq_tensor[idx], self.kinetics_tensor[idx], self.label_tensor[idx]\n",
        "         # sequence data (requires one-hot encoding)\n",
        "         seq_tensor_one_hot = F.one_hot(seq, num_classes=self.vocab_size).T\n",
        "         return {\n",
        "              'seq': seq_tensor_one_hot,\n",
        "              'kinetics': kinetics,\n",
        "              'label': label\n",
        "              }\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test out the dataset/dataloader"
      ],
      "metadata": {
        "id": "Sf7dRYVZKCAy"
      },
      "id": "Sf7dRYVZKCAy"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "542b46f9",
      "metadata": {
        "id": "542b46f9"
      },
      "outputs": [],
      "source": [
        "batch_size = 512\n",
        "\n",
        "train_ds = MethylDataset(train_parquet)\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "test_ds = MethylDataset(test_parquet)\n",
        "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "UJhPF-747iGY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJhPF-747iGY",
        "outputId": "2f7f79ce-dba6-4817-fd5d-ed8f6c8c151d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
              "         [  0,   0,   0,  ...,   0,   1,   0],\n",
              "         [  0,   0,   0,  ...,   1,   0,   0],\n",
              "         ...,\n",
              "         [ 43,  11,  14,  ...,  17,  10,  30],\n",
              "         [ 17,  27,  23,  ..., 116,  50,  64],\n",
              "         [ 59,  12,  18,  ...,  56,  40,  21]],\n",
              "\n",
              "        [[  0,   0,   0,  ...,   1,   0,   1],\n",
              "         [  0,   0,   0,  ...,   0,   0,   0],\n",
              "         [  0,   0,   1,  ...,   0,   0,   0],\n",
              "         ...,\n",
              "         [ 25,  22,  42,  ...,  18,  23,  21],\n",
              "         [ 69,  21,  21,  ...,  12,  13,  17],\n",
              "         [ 11,  45,  14,  ...,  28,  23,  28]],\n",
              "\n",
              "        [[  0,   1,   1,  ...,   0,   0,   0],\n",
              "         [  0,   0,   0,  ...,   1,   0,   0],\n",
              "         [  0,   0,   0,  ...,   0,   0,   1],\n",
              "         ...,\n",
              "         [ 15,  21,  17,  ...,  21,  20,  24],\n",
              "         [ 31,  24,  14,  ...,  13,  31,  25],\n",
              "         [ 40,  19,  13,  ...,  20,  24,  47]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[  1,   1,   1,  ...,   0,   1,   1],\n",
              "         [  0,   0,   0,  ...,   0,   0,   0],\n",
              "         [  0,   0,   0,  ...,   1,   0,   0],\n",
              "         ...,\n",
              "         [ 12,  23,  11,  ...,  49,  18,  14],\n",
              "         [ 18,  17,  18,  ...,  22,  12,  19],\n",
              "         [ 31,  20,  25,  ...,  26,  32,  34]],\n",
              "\n",
              "        [[  0,   0,   0,  ...,   0,   1,   1],\n",
              "         [  0,   1,   1,  ...,   1,   0,   0],\n",
              "         [  0,   0,   0,  ...,   0,   0,   0],\n",
              "         ...,\n",
              "         [ 12,   7,  41,  ...,  31,  29,   7],\n",
              "         [ 31,  43,  16,  ...,  15,  17,  17],\n",
              "         [ 38,  38,  22,  ...,  23,  31,  24]],\n",
              "\n",
              "        [[  0,   1,   1,  ...,   1,   0,   1],\n",
              "         [  0,   0,   0,  ...,   0,   1,   0],\n",
              "         [  0,   0,   0,  ...,   0,   0,   0],\n",
              "         ...,\n",
              "         [ 24,  12,  24,  ...,  13,  20,  12],\n",
              "         [ 12,  13,  22,  ...,   9,  19,  14],\n",
              "         [ 24,  33,  22,  ...,  28,  26,  37]]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "batch_example = next(iter(train_dl))\n",
        "torch.cat((batch_example['seq'], batch_example['kinetics']), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rIBO-1nnKK0w",
      "metadata": {
        "id": "rIBO-1nnKK0w"
      },
      "source": [
        "### Label distribution check\n",
        "\n",
        "Question: Are the classes evenly distributed?\n",
        "\n",
        "Test: Mean of label column should be 0.5\n",
        "\n",
        "Result: mean is very close to 0.5 -> classes are evenly distributed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "291377e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "291377e0",
        "outputId": "76f258bb-9df2-4e96-f2b0-06d43c9fa207"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5023785352982572, 1361342)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train_ds.df['label'].mean(), len(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "95376c97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95376c97",
        "outputId": "76bcb3c8-4629-48c1-8cb2-0a5b71fd4b2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.int64(32), np.int64(0))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "len_list = np.array([len(train_ds.df.row(i, named=True)['fi']) for i in range(len(train_ds))])\n",
        "np.min(len_list),np.argmin(len_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hjP5p6tDJ7hD",
      "metadata": {
        "id": "hjP5p6tDJ7hD"
      },
      "source": [
        "# Model Definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full model (nucleotides + kinetics)"
      ],
      "metadata": {
        "id": "1WrFe-iTKI64"
      },
      "id": "1WrFe-iTKI64"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "88af216c",
      "metadata": {
        "id": "88af216c"
      },
      "outputs": [],
      "source": [
        "class MethylCNN(nn.Module):\n",
        "    def __init__(self, sequence_length: int = 32, in_channels:int = 8, num_classes: int = 2, dropout_p: float = 0.5):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.sequence_length = sequence_length\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Convolution layers\n",
        "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=5, padding=1)\n",
        "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "\n",
        "        # calculate fc layer input with dummy passthrough\n",
        "        self.fc_input_features = self._get_conv_output_size(sequence_length)\n",
        "\n",
        "        # Linear layers\n",
        "        self.fc1 = nn.Linear(in_features=self.fc_input_features, out_features=64)\n",
        "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
        "        self.fc3 = nn.Linear(in_features=32, out_features=num_classes)\n",
        "\n",
        "        # dropout\n",
        "        self.dropout = nn.Dropout(p=dropout_p)\n",
        "\n",
        "    def _extract_features(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool1d(x, kernel_size=2, stride=2)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool1d(x, kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool1d(x, kernel_size=2, stride=2)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool1d(x, kernel_size=2, stride=2)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _get_conv_output_size(self, sequence_length: int) -> int:\n",
        "        \"\"\"\n",
        "        Calculates the flattened output size of the convolutional layers\n",
        "        by performing a forward pass on random data of the right shape.\n",
        "        \"\"\"\n",
        "        dummy_input = torch.randn(1, self.in_channels, sequence_length)\n",
        "        output = self._extract_features(dummy_input)\n",
        "        return output.numel()\n",
        "\n",
        "    def forward(self, batch: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "        seq = batch['seq']#.permute(0, 2, 1)\n",
        "        kinetics = batch['kinetics']#.unsqueeze(1)\n",
        "\n",
        "        # the input is a dictionary, so convert to a tensor\n",
        "        x = torch.cat([seq, kinetics], dim=1).to(self.conv1.weight.dtype) # -> [B, 8, L]\n",
        "\n",
        "        x = self._extract_features(x)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        logits = self.fc3(x)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resticted model (nucleotides only)"
      ],
      "metadata": {
        "id": "UovqidFgKMM4"
      },
      "id": "UovqidFgKMM4"
    },
    {
      "cell_type": "code",
      "source": [
        "class MethylCNN_Nucleotides(nn.Module):\n",
        "    def __init__(self, sequence_length: int = 32, in_channels:int = 4, num_classes: int = 2, dropout_p: float = 0.5):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.sequence_length = sequence_length\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Convolution layers\n",
        "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=8, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=8, out_channels=16, kernel_size=5, padding=1)\n",
        "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "\n",
        "        # calculate fc layer input with dummy passthrough\n",
        "        self.fc_input_features = self._get_conv_output_size(sequence_length)\n",
        "\n",
        "        # Linear layers\n",
        "        self.fc1 = nn.Linear(in_features=self.fc_input_features, out_features=64)\n",
        "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
        "        self.fc3 = nn.Linear(in_features=32, out_features=num_classes)\n",
        "\n",
        "        # dropout\n",
        "        self.dropout = nn.Dropout(p=dropout_p)\n",
        "\n",
        "    def _extract_features(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool1d(x, kernel_size=2, stride=2)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool1d(x, kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool1d(x, kernel_size=2, stride=2)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool1d(x, kernel_size=2, stride=2)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _get_conv_output_size(self, sequence_length: int) -> int:\n",
        "        \"\"\"\n",
        "        Calculates the flattened output size of the convolutional layers\n",
        "        by performing a forward pass on random data of the right shape.\n",
        "        \"\"\"\n",
        "        dummy_input = torch.randn(1, self.in_channels, sequence_length)\n",
        "        output = self._extract_features(dummy_input)\n",
        "        return output.numel()\n",
        "\n",
        "    def forward(self, batch: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "        seq = batch['seq']#.permute(0, 2, 1)\n",
        "        kinetics = batch['kinetics']#.unsqueeze(1)\n",
        "\n",
        "        # the input is a dictionary, so convert to a tensor\n",
        "        x = seq.to(self.conv1.weight.dtype)\n",
        "\n",
        "        x = self._extract_features(x)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        logits = self.fc3(x)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "5ii_w1RcsLlr"
      },
      "id": "5ii_w1RcsLlr",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Restricted model (kinetics only)"
      ],
      "metadata": {
        "id": "HksFs9jRKQna"
      },
      "id": "HksFs9jRKQna"
    },
    {
      "cell_type": "code",
      "source": [
        "class MethylCNN_Kinetics(nn.Module):\n",
        "    def __init__(self, sequence_length: int = 32, in_channels:int = 4, num_classes: int = 2, dropout_p: float = 0.5):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.sequence_length = sequence_length\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Convolution layers\n",
        "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=8, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=8, out_channels=16, kernel_size=5, padding=1)\n",
        "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "\n",
        "        # calculate fc layer input with dummy passthrough\n",
        "        self.fc_input_features = self._get_conv_output_size(sequence_length)\n",
        "\n",
        "        # Linear layers\n",
        "        self.fc1 = nn.Linear(in_features=self.fc_input_features, out_features=64)\n",
        "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
        "        self.fc3 = nn.Linear(in_features=32, out_features=num_classes)\n",
        "\n",
        "        # dropout\n",
        "        self.dropout = nn.Dropout(p=dropout_p)\n",
        "\n",
        "    def _extract_features(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool1d(x, kernel_size=2, stride=2)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool1d(x, kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool1d(x, kernel_size=2, stride=2)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool1d(x, kernel_size=2, stride=2)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _get_conv_output_size(self, sequence_length: int) -> int:\n",
        "        \"\"\"\n",
        "        Calculates the flattened output size of the convolutional layers\n",
        "        by performing a forward pass on random data of the right shape.\n",
        "        \"\"\"\n",
        "        dummy_input = torch.randn(1, self.in_channels, sequence_length)\n",
        "        output = self._extract_features(dummy_input)\n",
        "        return output.numel()\n",
        "\n",
        "    def forward(self, batch: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "        seq = batch['seq']#.permute(0, 2, 1)\n",
        "        kinetics = batch['kinetics']#.unsqueeze(1)\n",
        "\n",
        "        # the input is a dictionary, so convert to a tensor\n",
        "        x = kinetics.to(self.conv1.weight.dtype)\n",
        "\n",
        "        x = self._extract_features(x)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        logits = self.fc3(x)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "_X89Z5wTti1H"
      },
      "id": "_X89Z5wTti1H",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "lgsz4J35MMNU",
      "metadata": {
        "id": "lgsz4J35MMNU"
      },
      "source": [
        "# Eval Loop Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "0a778b26",
      "metadata": {
        "id": "0a778b26"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(\n",
        "    model: nn.Module,\n",
        "    data_loader: DataLoader,\n",
        "    criterion: nn.Module,\n",
        "    device: torch.device,\n",
        ") -> Dict[str, float]:\n",
        "    model.eval()\n",
        "    running_loss: float = 0.0\n",
        "    correct_predictions: int = 0\n",
        "    total_samples: int = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(data_loader):\n",
        "            labels: torch.Tensor = batch.pop(\"label\").to(device)\n",
        "            inputs: Dict[str, torch.Tensor] = {\n",
        "                k: v.to(device) for k, v in batch.items()\n",
        "            }\n",
        "\n",
        "            logits: torch.Tensor = model(inputs)\n",
        "            loss: torch.Tensor = criterion(logits, labels)\n",
        "\n",
        "            running_loss += loss.item() * labels.size(0)\n",
        "\n",
        "            _, predicted = torch.max(logits.data, 1)\n",
        "            total_samples += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss: float = running_loss / total_samples\n",
        "    epoch_acc: float = correct_predictions / total_samples\n",
        "    return {\"loss\": epoch_loss, \"accuracy\": epoch_acc}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_l0e7eYTJ4EC",
      "metadata": {
        "id": "_l0e7eYTJ4EC"
      },
      "source": [
        "# Training Loop\n",
        "## Things I'm thinking about\n",
        "### Batch sizes and training time\n",
        "At first training was really slow. It took around 4 minutes for one epoch at batch size 32, with a training dataset length of 1.3m examples. Gains were also slow, taking around 10 epochs to reach test set accuracy of 0.8. Not only that, I discovered that using an A100 GPU (big fancy gpu) was not any faster than a CPU! After thinking about it, I realized that my data is very small per sample, and so that gpu is completely unsaturated at this small of a batch size. That said, I was told that using a batch size above 64 leads to worse generalizability, since we miss out on a lot of the stochasticity in gradients that is inherent at smaller batch sizes. Despite that, I switched to larger and larger batch sizes, all the way to size 1024, which lowered the epoch training time to around 15 seconds, keeping everything else constant. The result is that we get test set accuracy of 0.8 after the same number of epochs, but in under 10 minutes. So it seems like generlizability was not damaged too bad, but I'm still wondering: What can we do to regains some of that stochasticity/generalizability that was lost? Some ideas:\n",
        "\n",
        "1. Increase the learning rate. I scaled the batch size by approx 100x, so maybe start with 10x learning rate.\n",
        "2. More dropout? I'm already using dropout on the linear layers with p=0.5\n",
        "3. Warmup with the learning rate, and then decay. Seems like the test set acc plateus around 0.834. Perhaps that could be solved by using a lower training rate at late"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(\n",
        "    model: nn.Module,\n",
        "    data_loader: DataLoader,\n",
        "    epochs,\n",
        "    criterion: nn.Module,\n",
        "    optimizer,\n",
        "    device: torch.device,\n",
        "    ) -> Dict[str, float]:\n",
        "\n",
        "    epoch_train_losses = []\n",
        "    epoch_test_losses = []\n",
        "    epoch_test_acc = []\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, batch in enumerate(tqdm(data_loader), 0):\n",
        "            # remove the label from batch\n",
        "            labels = batch.pop('label').to(device)\n",
        "            # dictionary of features, with features on device\n",
        "            inputs = {k: v.to(device) for k, v in batch.items()}\n",
        "            # zero grads\n",
        "            optimizer.zero_grad()\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # store training loss\n",
        "            running_loss += loss.item()\n",
        "        # calculate avg training epoch loss\n",
        "        avg_epoch_loss = running_loss/len(train_dl)\n",
        "        # add to running list\n",
        "        epoch_train_losses.append(avg_epoch_loss)\n",
        "        # get test set evaluation stats\n",
        "        eval_dict = evaluate_model(model, test_dl, criterion, device)\n",
        "        test_loss = eval_dict['loss']\n",
        "        test_acc = eval_dict['accuracy']\n",
        "        epoch_test_losses.append(test_loss)\n",
        "        epoch_test_acc.append(test_acc)\n",
        "        # print stats after each epoch\n",
        "        print(f' avg epoch train loss: {round(avg_epoch_loss, 4)}\\n test set loss: {round(test_loss,4)}\\n test set accuracy: {round(test_acc,4)}')\n",
        "\n",
        "    print(f'Completed training for {epochs} epochs')\n",
        "    return {'train_losses': epoch_train_losses, 'test_losses': epoch_test_losses, 'test_acc': epoch_test_acc}\n",
        "\n"
      ],
      "metadata": {
        "id": "hX3lgjZnaIJL"
      },
      "id": "hX3lgjZnaIJL",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Plot function"
      ],
      "metadata": {
        "id": "GZANE2KcQazH"
      },
      "id": "GZANE2KcQazH"
    },
    {
      "cell_type": "code",
      "source": [
        "def make_loss_plot(loss_stats: dict):\n",
        "  loss_df = pl.DataFrame({\n",
        "      'epoch': np.arange(len(loss_stats['train_losses'])),\n",
        "      'train_loss' : loss_stats['train_losses'],\n",
        "      'test_loss' : loss_stats['test_losses'],\n",
        "      'test_acc': loss_stats['test_acc']\n",
        "    })\n",
        "\n",
        "  loss_df_long = loss_df.drop(pl.col('test_acc')).unpivot(index='epoch', value_name='loss')\n",
        "\n",
        "  loss_chart = alt.Chart(loss_df_long).mark_line().encode(\n",
        "    alt.X('epoch:O'),\n",
        "    alt.Y('loss:Q', scale=alt.Scale(domain=(0.3, 0.57))),\n",
        "    alt.Color('variable')\n",
        "  ).properties(\n",
        "    width=700,\n",
        "    height=500,\n",
        "    title = 'Train and Test Loss Per Epoch'\n",
        "  )\n",
        "  acc_chart = alt.Chart(loss_df).mark_line().encode(\n",
        "    alt.X('epoch:O'),\n",
        "    alt.Y('test_acc:Q', scale=alt.Scale(domain=(0.4, 1.0)))\n",
        "  ).properties(\n",
        "    width=700,\n",
        "    height=500,\n",
        "    title = 'Test Set Prediction Accuracy Per Epoch'\n",
        "  )\n",
        "  return acc_chart | loss_chart"
      ],
      "metadata": {
        "id": "Ej_ZYcpQQaXA"
      },
      "id": "Ej_ZYcpQQaXA",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nucleotide only model training\n",
        "As hoped, the train/test loss stays at 0.69, indicating that even after 30 epochs, the model is still just guessing. This is good because we shouldn't be able to tell if a CG site is methylated unless we've polluted our data in some way making it not generalizable wild data."
      ],
      "metadata": {
        "id": "N_yMS2JvA2Ty"
      },
      "id": "N_yMS2JvA2Ty"
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = MethylDataset(train_parquet)\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "test_ds = MethylDataset(test_parquet)\n",
        "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "model_nucleotides = MethylCNN_Nucleotides(sequence_length=32)\n",
        "model_nucleotides.to(device)\n",
        "\n",
        "criterion_nucleotides = nn.CrossEntropyLoss()\n",
        "optimizer_nucleotides = torch.optim.Adam(model_nucleotides.parameters(), lr=0.002)\n",
        "\n",
        "training_stats_nucleotides = train_model(model_nucleotides, train_dl, epochs = 30, criterion=criterion_nucleotides, optimizer = optimizer_nucleotides, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vxmQeUfsdHa",
        "outputId": "46b9956a-3ab6-4d54-f83d-cf658c30429c"
      },
      "id": "6vxmQeUfsdHa",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:17<00:00, 154.78it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 173.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6931\n",
            " test set loss: 0.6929\n",
            " test set accuracy: 0.5084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 160.34it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 157.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6929\n",
            " test set loss: 0.6928\n",
            " test set accuracy: 0.5116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 162.12it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 166.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6928\n",
            " test set loss: 0.6927\n",
            " test set accuracy: 0.5122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 159.01it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 176.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6927\n",
            " test set loss: 0.6927\n",
            " test set accuracy: 0.5102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 165.02it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 165.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6927\n",
            " test set loss: 0.6927\n",
            " test set accuracy: 0.5113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 163.07it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 179.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6927\n",
            " test set loss: 0.6927\n",
            " test set accuracy: 0.5096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 163.23it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 161.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6926\n",
            " test set loss: 0.6926\n",
            " test set accuracy: 0.5109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 161.45it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 170.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6926\n",
            " test set loss: 0.6926\n",
            " test set accuracy: 0.5123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 161.24it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 168.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6926\n",
            " test set loss: 0.6928\n",
            " test set accuracy: 0.5114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 163.67it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 158.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6925\n",
            " test set loss: 0.6926\n",
            " test set accuracy: 0.5114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 161.58it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 159.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6925\n",
            " test set loss: 0.6926\n",
            " test set accuracy: 0.5112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 164.94it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 177.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6925\n",
            " test set loss: 0.6926\n",
            " test set accuracy: 0.5113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 164.05it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 160.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6925\n",
            " test set loss: 0.6926\n",
            " test set accuracy: 0.5111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 159.83it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 172.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6924\n",
            " test set loss: 0.6927\n",
            " test set accuracy: 0.5114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 160.99it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 174.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6924\n",
            " test set loss: 0.6926\n",
            " test set accuracy: 0.511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 164.89it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 158.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6924\n",
            " test set loss: 0.6925\n",
            " test set accuracy: 0.5119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 160.98it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 175.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6923\n",
            " test set loss: 0.6927\n",
            " test set accuracy: 0.5114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 162.70it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 174.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6923\n",
            " test set loss: 0.6925\n",
            " test set accuracy: 0.5113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 164.01it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 155.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6922\n",
            " test set loss: 0.6924\n",
            " test set accuracy: 0.5109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 160.43it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 166.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6921\n",
            " test set loss: 0.6924\n",
            " test set accuracy: 0.512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:17<00:00, 153.07it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 175.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6921\n",
            " test set loss: 0.6925\n",
            " test set accuracy: 0.5115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:17<00:00, 151.09it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 163.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.692\n",
            " test set loss: 0.6924\n",
            " test set accuracy: 0.5118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 162.37it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 147.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6919\n",
            " test set loss: 0.6923\n",
            " test set accuracy: 0.5121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 160.36it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 171.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6919\n",
            " test set loss: 0.6923\n",
            " test set accuracy: 0.511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 156.65it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 172.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6919\n",
            " test set loss: 0.6923\n",
            " test set accuracy: 0.5117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 162.43it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 159.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6918\n",
            " test set loss: 0.6924\n",
            " test set accuracy: 0.5113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 164.12it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 175.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6918\n",
            " test set loss: 0.6923\n",
            " test set accuracy: 0.512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 161.17it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 164.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6918\n",
            " test set loss: 0.6922\n",
            " test set accuracy: 0.5118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 163.57it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 167.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6917\n",
            " test set loss: 0.6923\n",
            " test set accuracy: 0.5122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:17<00:00, 155.78it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 169.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.6917\n",
            " test set loss: 0.6923\n",
            " test set accuracy: 0.5106\n",
            "Completed training for 30 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_loss_plot(training_stats_nucleotides)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "id": "0jdPASjhdWq_",
        "outputId": "a10756dd-9667-4817-b949-28753e3c4a38"
      },
      "id": "0jdPASjhdWq_",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "  #altair-viz-459aee824dba479197414483d482b293.vega-embed {\n",
              "    width: 100%;\n",
              "    display: flex;\n",
              "  }\n",
              "\n",
              "  #altair-viz-459aee824dba479197414483d482b293.vega-embed details,\n",
              "  #altair-viz-459aee824dba479197414483d482b293.vega-embed details summary {\n",
              "    position: relative;\n",
              "  }\n",
              "</style>\n",
              "<div id=\"altair-viz-459aee824dba479197414483d482b293\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-459aee824dba479197414483d482b293\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-459aee824dba479197414483d482b293\");\n",
              "    }\n",
              "\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function maybeLoadScript(lib, version) {\n",
              "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
              "      return (VEGA_DEBUG[key] == version) ?\n",
              "        Promise.resolve(paths[lib]) :\n",
              "        new Promise(function(resolve, reject) {\n",
              "          var s = document.createElement('script');\n",
              "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "          s.async = true;\n",
              "          s.onload = () => {\n",
              "            VEGA_DEBUG[key] = version;\n",
              "            return resolve(paths[lib]);\n",
              "          };\n",
              "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "          s.src = paths[lib];\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      let deps = [\"vega-embed\"];\n",
              "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else {\n",
              "      maybeLoadScript(\"vega\", \"5\")\n",
              "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
              "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"$schema\": \"https://vega.github.io/schema/vega/v5.json\", \"data\": [{\"name\": \"source_0\", \"values\": [{\"epoch\": 0, \"test_acc\": 0.5084431019842097}, {\"epoch\": 1, \"test_acc\": 0.5116193655112433}, {\"epoch\": 2, \"test_acc\": 0.5122422775072942}, {\"epoch\": 3, \"test_acc\": 0.510203122199467}, {\"epoch\": 4, \"test_acc\": 0.5113255390980117}, {\"epoch\": 5, \"test_acc\": 0.5095508275620929}, {\"epoch\": 6, \"test_acc\": 0.5109053673270905}, {\"epoch\": 7, \"test_acc\": 0.5122892897334113}, {\"epoch\": 8, \"test_acc\": 0.5114254400785104}, {\"epoch\": 9, \"test_acc\": 0.5113637365317318}, {\"epoch\": 10, \"test_acc\": 0.5112138850609836}, {\"epoch\": 11, \"test_acc\": 0.5112579590229684}, {\"epoch\": 12, \"test_acc\": 0.511096354495691}, {\"epoch\": 13, \"test_acc\": 0.5113725513241287}, {\"epoch\": 14, \"test_acc\": 0.511040527477177}, {\"epoch\": 15, \"test_acc\": 0.5118749944907548}, {\"epoch\": 16, \"test_acc\": 0.5113901809089226}, {\"epoch\": 17, \"test_acc\": 0.5112579590229684}, {\"epoch\": 18, \"test_acc\": 0.510873046421635}, {\"epoch\": 19, \"test_acc\": 0.5119954633201798}, {\"epoch\": 20, \"test_acc\": 0.5115459089079354}, {\"epoch\": 21, \"test_acc\": 0.511775093510256}, {\"epoch\": 22, \"test_acc\": 0.5120894877724138}, {\"epoch\": 23, \"test_acc\": 0.5109523795532076}, {\"epoch\": 24, \"test_acc\": 0.5116928221145511}, {\"epoch\": 25, \"test_acc\": 0.5112932181925562}, {\"epoch\": 26, \"test_acc\": 0.512007216376709}, {\"epoch\": 27, \"test_acc\": 0.5118367970570347}, {\"epoch\": 28, \"test_acc\": 0.5122070183377064}, {\"epoch\": 29, \"test_acc\": 0.5106438618193144}]}, {\"name\": \"source_1\", \"values\": [{\"epoch\": 0, \"variable\": \"train_loss\", \"loss\": 0.6931166920997273}, {\"epoch\": 1, \"variable\": \"train_loss\", \"loss\": 0.6928724959049963}, {\"epoch\": 2, \"variable\": \"train_loss\", \"loss\": 0.6927714608091302}, {\"epoch\": 3, \"variable\": \"train_loss\", \"loss\": 0.692711823929876}, {\"epoch\": 4, \"variable\": \"train_loss\", \"loss\": 0.6926821216285206}, {\"epoch\": 5, \"variable\": \"train_loss\", \"loss\": 0.6926636945353992}, {\"epoch\": 6, \"variable\": \"train_loss\", \"loss\": 0.6926412123089762}, {\"epoch\": 7, \"variable\": \"train_loss\", \"loss\": 0.6926108894378631}, {\"epoch\": 8, \"variable\": \"train_loss\", \"loss\": 0.692589126479675}, {\"epoch\": 9, \"variable\": \"train_loss\", \"loss\": 0.6925460385307866}, {\"epoch\": 10, \"variable\": \"train_loss\", \"loss\": 0.6925199014121045}, {\"epoch\": 11, \"variable\": \"train_loss\", \"loss\": 0.6925208371310541}, {\"epoch\": 12, \"variable\": \"train_loss\", \"loss\": 0.6924676448162806}, {\"epoch\": 13, \"variable\": \"train_loss\", \"loss\": 0.6924470025105959}, {\"epoch\": 14, \"variable\": \"train_loss\", \"loss\": 0.6924275094604707}, {\"epoch\": 15, \"variable\": \"train_loss\", \"loss\": 0.6923751493242729}, {\"epoch\": 16, \"variable\": \"train_loss\", \"loss\": 0.6923114196076883}, {\"epoch\": 17, \"variable\": \"train_loss\", \"loss\": 0.6922583910431706}, {\"epoch\": 18, \"variable\": \"train_loss\", \"loss\": 0.6921804367307883}, {\"epoch\": 19, \"variable\": \"train_loss\", \"loss\": 0.6921108602446333}, {\"epoch\": 20, \"variable\": \"train_loss\", \"loss\": 0.6920562313211821}, {\"epoch\": 21, \"variable\": \"train_loss\", \"loss\": 0.6920001932040513}, {\"epoch\": 22, \"variable\": \"train_loss\", \"loss\": 0.6919365978725156}, {\"epoch\": 23, \"variable\": \"train_loss\", \"loss\": 0.6919033080395472}, {\"epoch\": 24, \"variable\": \"train_loss\", \"loss\": 0.6918647134828585}, {\"epoch\": 25, \"variable\": \"train_loss\", \"loss\": 0.6918346885677207}, {\"epoch\": 26, \"variable\": \"train_loss\", \"loss\": 0.6917768655391777}, {\"epoch\": 27, \"variable\": \"train_loss\", \"loss\": 0.6917861471188701}, {\"epoch\": 28, \"variable\": \"train_loss\", \"loss\": 0.691689665692334}, {\"epoch\": 29, \"variable\": \"train_loss\", \"loss\": 0.691700016905285}, {\"epoch\": 0, \"variable\": \"test_loss\", \"loss\": 0.6929057498171587}, {\"epoch\": 1, \"variable\": \"test_loss\", \"loss\": 0.6927731657650835}, {\"epoch\": 2, \"variable\": \"test_loss\", \"loss\": 0.6926909249129566}, {\"epoch\": 3, \"variable\": \"test_loss\", \"loss\": 0.6927457325919907}, {\"epoch\": 4, \"variable\": \"test_loss\", \"loss\": 0.6926556467257222}, {\"epoch\": 5, \"variable\": \"test_loss\", \"loss\": 0.6927363573710619}, {\"epoch\": 6, \"variable\": \"test_loss\", \"loss\": 0.6926389853088248}, {\"epoch\": 7, \"variable\": \"test_loss\", \"loss\": 0.6926291085352756}, {\"epoch\": 8, \"variable\": \"test_loss\", \"loss\": 0.6927864751719066}, {\"epoch\": 9, \"variable\": \"test_loss\", \"loss\": 0.6926266489904686}, {\"epoch\": 10, \"variable\": \"test_loss\", \"loss\": 0.6925793441256283}, {\"epoch\": 11, \"variable\": \"test_loss\", \"loss\": 0.6925561091917505}, {\"epoch\": 12, \"variable\": \"test_loss\", \"loss\": 0.6925934525955028}, {\"epoch\": 13, \"variable\": \"test_loss\", \"loss\": 0.6926537685542703}, {\"epoch\": 14, \"variable\": \"test_loss\", \"loss\": 0.6926403671909641}, {\"epoch\": 15, \"variable\": \"test_loss\", \"loss\": 0.6925168971203781}, {\"epoch\": 16, \"variable\": \"test_loss\", \"loss\": 0.6926618848034602}, {\"epoch\": 17, \"variable\": \"test_loss\", \"loss\": 0.6924520247139572}, {\"epoch\": 18, \"variable\": \"test_loss\", \"loss\": 0.6924110085583244}, {\"epoch\": 19, \"variable\": \"test_loss\", \"loss\": 0.6923996635630565}, {\"epoch\": 20, \"variable\": \"test_loss\", \"loss\": 0.6924631134038409}, {\"epoch\": 21, \"variable\": \"test_loss\", \"loss\": 0.6924400097417951}, {\"epoch\": 22, \"variable\": \"test_loss\", \"loss\": 0.6922815719406753}, {\"epoch\": 23, \"variable\": \"test_loss\", \"loss\": 0.6922787575401987}, {\"epoch\": 24, \"variable\": \"test_loss\", \"loss\": 0.6923364609730434}, {\"epoch\": 25, \"variable\": \"test_loss\", \"loss\": 0.6924226637066102}, {\"epoch\": 26, \"variable\": \"test_loss\", \"loss\": 0.6922645278790411}, {\"epoch\": 27, \"variable\": \"test_loss\", \"loss\": 0.6921825479983985}, {\"epoch\": 28, \"variable\": \"test_loss\", \"loss\": 0.6923127141700904}, {\"epoch\": 29, \"variable\": \"test_loss\", \"loss\": 0.6922521506085317}]}, {\"name\": \"source_1_color_domain_variable\", \"values\": [{\"variable\": \"train_loss\"}, {\"variable\": \"test_loss\"}]}, {\"name\": \"source_0_concat_0_x_domain_epoch\", \"values\": [{\"epoch\": 0}, {\"epoch\": 1}, {\"epoch\": 2}, {\"epoch\": 3}, {\"epoch\": 4}, {\"epoch\": 5}, {\"epoch\": 6}, {\"epoch\": 7}, {\"epoch\": 8}, {\"epoch\": 9}, {\"epoch\": 10}, {\"epoch\": 11}, {\"epoch\": 12}, {\"epoch\": 13}, {\"epoch\": 14}, {\"epoch\": 15}, {\"epoch\": 16}, {\"epoch\": 17}, {\"epoch\": 18}, {\"epoch\": 19}, {\"epoch\": 20}, {\"epoch\": 21}, {\"epoch\": 22}, {\"epoch\": 23}, {\"epoch\": 24}, {\"epoch\": 25}, {\"epoch\": 26}, {\"epoch\": 27}, {\"epoch\": 28}, {\"epoch\": 29}]}, {\"name\": \"source_1_concat_1_x_domain_epoch\", \"values\": [{\"epoch\": 0}, {\"epoch\": 1}, {\"epoch\": 2}, {\"epoch\": 3}, {\"epoch\": 4}, {\"epoch\": 5}, {\"epoch\": 6}, {\"epoch\": 7}, {\"epoch\": 8}, {\"epoch\": 9}, {\"epoch\": 10}, {\"epoch\": 11}, {\"epoch\": 12}, {\"epoch\": 13}, {\"epoch\": 14}, {\"epoch\": 15}, {\"epoch\": 16}, {\"epoch\": 17}, {\"epoch\": 18}, {\"epoch\": 19}, {\"epoch\": 20}, {\"epoch\": 21}, {\"epoch\": 22}, {\"epoch\": 23}, {\"epoch\": 24}, {\"epoch\": 25}, {\"epoch\": 26}, {\"epoch\": 27}, {\"epoch\": 28}, {\"epoch\": 29}]}], \"signals\": [{\"name\": \"childWidth\", \"value\": 700}], \"marks\": [{\"type\": \"group\", \"name\": \"concat_0_group\", \"encode\": {\"update\": {\"width\": {\"signal\": \"childWidth\"}, \"height\": {\"signal\": \"height\"}}}, \"marks\": [{\"type\": \"line\", \"name\": \"concat_0_marks\", \"from\": {\"data\": \"source_0\"}, \"sort\": {\"field\": \"x\"}, \"encode\": {\"update\": {\"stroke\": {\"value\": \"#4c78a8\"}, \"x\": {\"field\": \"epoch\", \"scale\": \"concat_0_x\"}, \"defined\": {\"signal\": \"isValid(datum[\\\"test_acc\\\"]) && isFinite(+datum[\\\"test_acc\\\"])\"}, \"y\": {\"field\": \"test_acc\", \"scale\": \"concat_0_y\"}}}, \"style\": [\"line\"]}], \"axes\": [{\"scale\": \"concat_0_y\", \"grid\": true, \"aria\": false, \"gridScale\": \"concat_0_x\", \"domain\": false, \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"labels\": false, \"orient\": \"left\", \"minExtent\": 0, \"zindex\": 0, \"maxExtent\": 0, \"ticks\": false}, {\"scale\": \"concat_0_x\", \"orient\": \"bottom\", \"labelBaseline\": \"middle\", \"zindex\": 0, \"labelAlign\": \"right\", \"title\": \"epoch\", \"grid\": false, \"labelAngle\": 270}, {\"scale\": \"concat_0_y\", \"zindex\": 0, \"title\": \"test_acc\", \"grid\": false, \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"labelOverlap\": true, \"orient\": \"left\"}], \"title\": {\"text\": \"Test Set Prediction Accuracy Per Epoch\", \"frame\": \"group\"}, \"style\": \"cell\"}, {\"type\": \"group\", \"name\": \"concat_1_group\", \"encode\": {\"update\": {\"width\": {\"signal\": \"childWidth\"}, \"height\": {\"signal\": \"height\"}}}, \"marks\": [{\"type\": \"group\", \"name\": \"concat_1_pathgroup\", \"from\": {\"facet\": {\"data\": \"source_1\", \"name\": \"faceted_path_concat_1_main\", \"groupby\": [\"variable\"]}}, \"encode\": {\"update\": {\"width\": {\"field\": {\"signal\": null, \"datum\": null, \"group\": \"width\", \"parent\": null}}, \"height\": {\"field\": {\"signal\": null, \"datum\": null, \"group\": \"height\", \"parent\": null}}}}, \"marks\": [{\"type\": \"line\", \"name\": \"concat_1_marks\", \"from\": {\"data\": \"faceted_path_concat_1_main\"}, \"sort\": {\"field\": \"x\"}, \"encode\": {\"update\": {\"x\": {\"field\": \"epoch\", \"scale\": \"concat_1_x\"}, \"stroke\": {\"field\": \"variable\", \"scale\": \"color\"}, \"defined\": {\"signal\": \"isValid(datum[\\\"loss\\\"]) && isFinite(+datum[\\\"loss\\\"])\"}, \"y\": {\"field\": \"loss\", \"scale\": \"concat_1_y\"}}}, \"style\": [\"line\"]}]}], \"axes\": [{\"scale\": \"concat_1_y\", \"ticks\": false, \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"orient\": \"left\", \"aria\": false, \"grid\": true, \"domain\": false, \"labels\": false, \"maxExtent\": 0, \"gridScale\": \"concat_1_x\", \"minExtent\": 0, \"zindex\": 0}, {\"scale\": \"concat_1_x\", \"labelAngle\": 270, \"labelBaseline\": \"middle\", \"zindex\": 0, \"title\": \"epoch\", \"grid\": false, \"orient\": \"bottom\", \"labelAlign\": \"right\"}, {\"scale\": \"concat_1_y\", \"title\": \"loss\", \"grid\": false, \"labelOverlap\": true, \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"zindex\": 0, \"orient\": \"left\"}], \"title\": {\"text\": \"Train and Test Loss Per Epoch\", \"frame\": \"group\"}, \"style\": \"cell\"}], \"scales\": [{\"name\": \"color\", \"type\": \"ordinal\", \"domain\": {\"data\": \"source_1_color_domain_variable\", \"field\": \"variable\", \"sort\": true}, \"range\": \"category\"}, {\"name\": \"concat_0_x\", \"type\": \"point\", \"domain\": {\"data\": \"source_0_concat_0_x_domain_epoch\", \"field\": \"epoch\", \"sort\": true}, \"range\": [0, {\"signal\": \"childWidth\"}], \"padding\": 0.5}, {\"name\": \"concat_0_y\", \"type\": \"linear\", \"domain\": [0.4, 1], \"range\": [{\"signal\": \"height\"}, 0], \"zero\": false}, {\"name\": \"concat_1_x\", \"type\": \"point\", \"domain\": {\"data\": \"source_1_concat_1_x_domain_epoch\", \"field\": \"epoch\", \"sort\": true}, \"range\": [0, {\"signal\": \"childWidth\"}], \"padding\": 0.5}, {\"name\": \"concat_1_y\", \"type\": \"linear\", \"domain\": [0.3, 0.57], \"range\": [{\"signal\": \"height\"}, 0], \"zero\": false}], \"legends\": [{\"stroke\": \"color\", \"symbolType\": \"stroke\", \"title\": \"variable\"}], \"background\": \"white\", \"height\": 500, \"layout\": {\"padding\": 20, \"bounds\": \"full\", \"align\": \"each\"}, \"padding\": 5}, {\"mode\": \"vega\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.HConcatChart(...)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kinetics only model training"
      ],
      "metadata": {
        "id": "lNdB2ZdQA7GB"
      },
      "id": "lNdB2ZdQA7GB"
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = MethylDataset(train_parquet)\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "test_ds = MethylDataset(test_parquet)\n",
        "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "model_kinetics = MethylCNN_Kinetics(sequence_length=32)\n",
        "model_kinetics.to(device)\n",
        "\n",
        "criterion_kinetics = nn.CrossEntropyLoss()\n",
        "optimizer_kinetics = torch.optim.Adam(model_kinetics.parameters(), lr=0.002)\n",
        "\n",
        "training_stats_kinetics = train_model(model_kinetics, train_dl, epochs = 30, criterion=criterion_kinetics, optimizer = optimizer_kinetics, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVS-BWVwt-yn",
        "outputId": "79867ed3-f039-4fb0-e56a-be9ac79aa9c1"
      },
      "id": "rVS-BWVwt-yn",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:17<00:00, 155.83it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 168.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.5465\n",
            " test set loss: 0.5184\n",
            " test set accuracy: 0.7442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 163.74it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 174.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.5085\n",
            " test set loss: 0.506\n",
            " test set accuracy: 0.7506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 158.97it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 170.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.5026\n",
            " test set loss: 0.4983\n",
            " test set accuracy: 0.7546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 162.36it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 164.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4986\n",
            " test set loss: 0.4964\n",
            " test set accuracy: 0.7563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 158.82it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 171.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.496\n",
            " test set loss: 0.4999\n",
            " test set accuracy: 0.7537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 162.42it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 167.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4949\n",
            " test set loss: 0.4977\n",
            " test set accuracy: 0.7545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 162.62it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 164.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4934\n",
            " test set loss: 0.493\n",
            " test set accuracy: 0.7595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 158.47it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 170.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4924\n",
            " test set loss: 0.4906\n",
            " test set accuracy: 0.7605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:17<00:00, 153.61it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 174.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4918\n",
            " test set loss: 0.4897\n",
            " test set accuracy: 0.7612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 158.73it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 168.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4915\n",
            " test set loss: 0.497\n",
            " test set accuracy: 0.7566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 161.56it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 170.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4905\n",
            " test set loss: 0.491\n",
            " test set accuracy: 0.7603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 161.94it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 173.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4901\n",
            " test set loss: 0.4978\n",
            " test set accuracy: 0.7569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 159.98it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 166.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4899\n",
            " test set loss: 0.4896\n",
            " test set accuracy: 0.7607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 159.87it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 155.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4893\n",
            " test set loss: 0.4886\n",
            " test set accuracy: 0.762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 157.66it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 162.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4891\n",
            " test set loss: 0.4913\n",
            " test set accuracy: 0.7601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:17<00:00, 153.24it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 168.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4888\n",
            " test set loss: 0.4891\n",
            " test set accuracy: 0.7618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 156.83it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 152.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4887\n",
            " test set loss: 0.4873\n",
            " test set accuracy: 0.7628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:17<00:00, 152.82it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 169.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4883\n",
            " test set loss: 0.4902\n",
            " test set accuracy: 0.7608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:17<00:00, 155.64it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 173.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4881\n",
            " test set loss: 0.4872\n",
            " test set accuracy: 0.7625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 159.80it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 162.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4878\n",
            " test set loss: 0.493\n",
            " test set accuracy: 0.758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 159.94it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 175.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4876\n",
            " test set loss: 0.489\n",
            " test set accuracy: 0.7623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 160.41it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 172.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4877\n",
            " test set loss: 0.4884\n",
            " test set accuracy: 0.7613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 157.45it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 156.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4874\n",
            " test set loss: 0.4867\n",
            " test set accuracy: 0.7628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 158.46it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 169.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.487\n",
            " test set loss: 0.4867\n",
            " test set accuracy: 0.7631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:17<00:00, 156.36it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 171.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4867\n",
            " test set loss: 0.4871\n",
            " test set accuracy: 0.761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 160.16it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 161.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4864\n",
            " test set loss: 0.4856\n",
            " test set accuracy: 0.764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 160.82it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 160.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4861\n",
            " test set loss: 0.4856\n",
            " test set accuracy: 0.764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 158.63it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 168.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.486\n",
            " test set loss: 0.4868\n",
            " test set accuracy: 0.7626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 159.73it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 162.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4859\n",
            " test set loss: 0.4866\n",
            " test set accuracy: 0.7641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 159.68it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 162.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4858\n",
            " test set loss: 0.4892\n",
            " test set accuracy: 0.7619\n",
            "Completed training for 30 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_loss_plot(training_stats_kinetics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "C_0ckt2Xddew",
        "outputId": "ac4d8682-15ae-4137-ec3c-9d323041ca39"
      },
      "id": "C_0ckt2Xddew",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "  #altair-viz-ae1853ce8cb347ca8fb17fd517bafe14.vega-embed {\n",
              "    width: 100%;\n",
              "    display: flex;\n",
              "  }\n",
              "\n",
              "  #altair-viz-ae1853ce8cb347ca8fb17fd517bafe14.vega-embed details,\n",
              "  #altair-viz-ae1853ce8cb347ca8fb17fd517bafe14.vega-embed details summary {\n",
              "    position: relative;\n",
              "  }\n",
              "</style>\n",
              "<div id=\"altair-viz-ae1853ce8cb347ca8fb17fd517bafe14\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-ae1853ce8cb347ca8fb17fd517bafe14\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-ae1853ce8cb347ca8fb17fd517bafe14\");\n",
              "    }\n",
              "\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function maybeLoadScript(lib, version) {\n",
              "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
              "      return (VEGA_DEBUG[key] == version) ?\n",
              "        Promise.resolve(paths[lib]) :\n",
              "        new Promise(function(resolve, reject) {\n",
              "          var s = document.createElement('script');\n",
              "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "          s.async = true;\n",
              "          s.onload = () => {\n",
              "            VEGA_DEBUG[key] = version;\n",
              "            return resolve(paths[lib]);\n",
              "          };\n",
              "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "          s.src = paths[lib];\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      let deps = [\"vega-embed\"];\n",
              "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else {\n",
              "      maybeLoadScript(\"vega\", \"5\")\n",
              "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
              "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"$schema\": \"https://vega.github.io/schema/vega/v5.json\", \"data\": [{\"name\": \"source_0\", \"values\": [{\"epoch\": 0, \"test_acc\": 0.7442387986025616}, {\"epoch\": 1, \"test_acc\": 0.7505531282229084}, {\"epoch\": 2, \"test_acc\": 0.7546167475179014}, {\"epoch\": 3, \"test_acc\": 0.7563444468277031}, {\"epoch\": 4, \"test_acc\": 0.7537147004292803}, {\"epoch\": 5, \"test_acc\": 0.7544522047264917}, {\"epoch\": 6, \"test_acc\": 0.7594795746568842}, {\"epoch\": 7, \"test_acc\": 0.7604697696694747}, {\"epoch\": 8, \"test_acc\": 0.7611896443818921}, {\"epoch\": 9, \"test_acc\": 0.7565795079582884}, {\"epoch\": 10, \"test_acc\": 0.7602729059726095}, {\"epoch\": 11, \"test_acc\": 0.7568674578432554}, {\"epoch\": 12, \"test_acc\": 0.7606666333663399}, {\"epoch\": 13, \"test_acc\": 0.7619800374334851}, {\"epoch\": 14, \"test_acc\": 0.7601201162377291}, {\"epoch\": 15, \"test_acc\": 0.7618008033214138}, {\"epoch\": 16, \"test_acc\": 0.7627733687492103}, {\"epoch\": 17, \"test_acc\": 0.7607812256675002}, {\"epoch\": 18, \"test_acc\": 0.7625412458827574}, {\"epoch\": 19, \"test_acc\": 0.758045701760314}, {\"epoch\": 20, \"test_acc\": 0.7623032464880398}, {\"epoch\": 21, \"test_acc\": 0.7613306810602433}, {\"epoch\": 22, \"test_acc\": 0.7628056896546658}, {\"epoch\": 23, \"test_acc\": 0.763123022180956}, {\"epoch\": 24, \"test_acc\": 0.7609604597795714}, {\"epoch\": 25, \"test_acc\": 0.7639574891945337}, {\"epoch\": 26, \"test_acc\": 0.7639898100999891}, {\"epoch\": 27, \"test_acc\": 0.7625911963730068}, {\"epoch\": 28, \"test_acc\": 0.7640691432315616}, {\"epoch\": 29, \"test_acc\": 0.761941839999765}]}, {\"name\": \"source_1\", \"values\": [{\"epoch\": 0, \"variable\": \"train_loss\", \"loss\": 0.5465049135164911}, {\"epoch\": 1, \"variable\": \"train_loss\", \"loss\": 0.50851038352759}, {\"epoch\": 2, \"variable\": \"train_loss\", \"loss\": 0.502635422350097}, {\"epoch\": 3, \"variable\": \"train_loss\", \"loss\": 0.49855916619569834}, {\"epoch\": 4, \"variable\": \"train_loss\", \"loss\": 0.4960403129564904}, {\"epoch\": 5, \"variable\": \"train_loss\", \"loss\": 0.494864994374914}, {\"epoch\": 6, \"variable\": \"train_loss\", \"loss\": 0.493416775523742}, {\"epoch\": 7, \"variable\": \"train_loss\", \"loss\": 0.49240628440786277}, {\"epoch\": 8, \"variable\": \"train_loss\", \"loss\": 0.49178154344574854}, {\"epoch\": 9, \"variable\": \"train_loss\", \"loss\": 0.4915325962183573}, {\"epoch\": 10, \"variable\": \"train_loss\", \"loss\": 0.4905425539788737}, {\"epoch\": 11, \"variable\": \"train_loss\", \"loss\": 0.4901303597951841}, {\"epoch\": 12, \"variable\": \"train_loss\", \"loss\": 0.4899095174243191}, {\"epoch\": 13, \"variable\": \"train_loss\", \"loss\": 0.4893225671071314}, {\"epoch\": 14, \"variable\": \"train_loss\", \"loss\": 0.48914650166648904}, {\"epoch\": 15, \"variable\": \"train_loss\", \"loss\": 0.4887913588004347}, {\"epoch\": 16, \"variable\": \"train_loss\", \"loss\": 0.48870905223938255}, {\"epoch\": 17, \"variable\": \"train_loss\", \"loss\": 0.4882767761323003}, {\"epoch\": 18, \"variable\": \"train_loss\", \"loss\": 0.48807271916017175}, {\"epoch\": 19, \"variable\": \"train_loss\", \"loss\": 0.4877781953834958}, {\"epoch\": 20, \"variable\": \"train_loss\", \"loss\": 0.48757197123669554}, {\"epoch\": 21, \"variable\": \"train_loss\", \"loss\": 0.48769979179465894}, {\"epoch\": 22, \"variable\": \"train_loss\", \"loss\": 0.48740562501819834}, {\"epoch\": 23, \"variable\": \"train_loss\", \"loss\": 0.4870201380416925}, {\"epoch\": 24, \"variable\": \"train_loss\", \"loss\": 0.4866867245319599}, {\"epoch\": 25, \"variable\": \"train_loss\", \"loss\": 0.4864163661908727}, {\"epoch\": 26, \"variable\": \"train_loss\", \"loss\": 0.48607270758642473}, {\"epoch\": 27, \"variable\": \"train_loss\", \"loss\": 0.4860484427238327}, {\"epoch\": 28, \"variable\": \"train_loss\", \"loss\": 0.4858995986168615}, {\"epoch\": 29, \"variable\": \"train_loss\", \"loss\": 0.48576724185177866}, {\"epoch\": 0, \"variable\": \"test_loss\", \"loss\": 0.5183655256103996}, {\"epoch\": 1, \"variable\": \"test_loss\", \"loss\": 0.5060085832039195}, {\"epoch\": 2, \"variable\": \"test_loss\", \"loss\": 0.49834933538684556}, {\"epoch\": 3, \"variable\": \"test_loss\", \"loss\": 0.49641835431116665}, {\"epoch\": 4, \"variable\": \"test_loss\", \"loss\": 0.49988607606747654}, {\"epoch\": 5, \"variable\": \"test_loss\", \"loss\": 0.49766596002149194}, {\"epoch\": 6, \"variable\": \"test_loss\", \"loss\": 0.4930316465635245}, {\"epoch\": 7, \"variable\": \"test_loss\", \"loss\": 0.4905593051730208}, {\"epoch\": 8, \"variable\": \"test_loss\", \"loss\": 0.48969434158454855}, {\"epoch\": 9, \"variable\": \"test_loss\", \"loss\": 0.49697646510895727}, {\"epoch\": 10, \"variable\": \"test_loss\", \"loss\": 0.4910151051876437}, {\"epoch\": 11, \"variable\": \"test_loss\", \"loss\": 0.49779888961472474}, {\"epoch\": 12, \"variable\": \"test_loss\", \"loss\": 0.48955229438805153}, {\"epoch\": 13, \"variable\": \"test_loss\", \"loss\": 0.4885693613833839}, {\"epoch\": 14, \"variable\": \"test_loss\", \"loss\": 0.49132347199702175}, {\"epoch\": 15, \"variable\": \"test_loss\", \"loss\": 0.4890950696518028}, {\"epoch\": 16, \"variable\": \"test_loss\", \"loss\": 0.4872643277505508}, {\"epoch\": 17, \"variable\": \"test_loss\", \"loss\": 0.4901590473289456}, {\"epoch\": 18, \"variable\": \"test_loss\", \"loss\": 0.48724704716660294}, {\"epoch\": 19, \"variable\": \"test_loss\", \"loss\": 0.4929966647505381}, {\"epoch\": 20, \"variable\": \"test_loss\", \"loss\": 0.48902706212148833}, {\"epoch\": 21, \"variable\": \"test_loss\", \"loss\": 0.48841363120009756}, {\"epoch\": 22, \"variable\": \"test_loss\", \"loss\": 0.4866647364232187}, {\"epoch\": 23, \"variable\": \"test_loss\", \"loss\": 0.48666111768149656}, {\"epoch\": 24, \"variable\": \"test_loss\", \"loss\": 0.4871052146439916}, {\"epoch\": 25, \"variable\": \"test_loss\", \"loss\": 0.48556843827355217}, {\"epoch\": 26, \"variable\": \"test_loss\", \"loss\": 0.48559364211345385}, {\"epoch\": 27, \"variable\": \"test_loss\", \"loss\": 0.48677446750969705}, {\"epoch\": 28, \"variable\": \"test_loss\", \"loss\": 0.4865514889879229}, {\"epoch\": 29, \"variable\": \"test_loss\", \"loss\": 0.4891510635467545}]}, {\"name\": \"source_1_color_domain_variable\", \"values\": [{\"variable\": \"train_loss\"}, {\"variable\": \"test_loss\"}]}, {\"name\": \"source_0_concat_0_x_domain_epoch\", \"values\": [{\"epoch\": 0}, {\"epoch\": 1}, {\"epoch\": 2}, {\"epoch\": 3}, {\"epoch\": 4}, {\"epoch\": 5}, {\"epoch\": 6}, {\"epoch\": 7}, {\"epoch\": 8}, {\"epoch\": 9}, {\"epoch\": 10}, {\"epoch\": 11}, {\"epoch\": 12}, {\"epoch\": 13}, {\"epoch\": 14}, {\"epoch\": 15}, {\"epoch\": 16}, {\"epoch\": 17}, {\"epoch\": 18}, {\"epoch\": 19}, {\"epoch\": 20}, {\"epoch\": 21}, {\"epoch\": 22}, {\"epoch\": 23}, {\"epoch\": 24}, {\"epoch\": 25}, {\"epoch\": 26}, {\"epoch\": 27}, {\"epoch\": 28}, {\"epoch\": 29}]}, {\"name\": \"source_1_concat_1_x_domain_epoch\", \"values\": [{\"epoch\": 0}, {\"epoch\": 1}, {\"epoch\": 2}, {\"epoch\": 3}, {\"epoch\": 4}, {\"epoch\": 5}, {\"epoch\": 6}, {\"epoch\": 7}, {\"epoch\": 8}, {\"epoch\": 9}, {\"epoch\": 10}, {\"epoch\": 11}, {\"epoch\": 12}, {\"epoch\": 13}, {\"epoch\": 14}, {\"epoch\": 15}, {\"epoch\": 16}, {\"epoch\": 17}, {\"epoch\": 18}, {\"epoch\": 19}, {\"epoch\": 20}, {\"epoch\": 21}, {\"epoch\": 22}, {\"epoch\": 23}, {\"epoch\": 24}, {\"epoch\": 25}, {\"epoch\": 26}, {\"epoch\": 27}, {\"epoch\": 28}, {\"epoch\": 29}]}], \"signals\": [{\"name\": \"childWidth\", \"value\": 700}], \"marks\": [{\"type\": \"group\", \"name\": \"concat_0_group\", \"encode\": {\"update\": {\"width\": {\"signal\": \"childWidth\"}, \"height\": {\"signal\": \"height\"}}}, \"marks\": [{\"type\": \"line\", \"name\": \"concat_0_marks\", \"from\": {\"data\": \"source_0\"}, \"sort\": {\"field\": \"x\"}, \"encode\": {\"update\": {\"y\": {\"field\": \"test_acc\", \"scale\": \"concat_0_y\"}, \"x\": {\"field\": \"epoch\", \"scale\": \"concat_0_x\"}, \"defined\": {\"signal\": \"isValid(datum[\\\"test_acc\\\"]) && isFinite(+datum[\\\"test_acc\\\"])\"}, \"stroke\": {\"value\": \"#4c78a8\"}}}, \"style\": [\"line\"]}], \"axes\": [{\"scale\": \"concat_0_y\", \"domain\": false, \"labels\": false, \"minExtent\": 0, \"ticks\": false, \"orient\": \"left\", \"grid\": true, \"aria\": false, \"maxExtent\": 0, \"gridScale\": \"concat_0_x\", \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"zindex\": 0}, {\"scale\": \"concat_0_x\", \"labelBaseline\": \"middle\", \"zindex\": 0, \"title\": \"epoch\", \"grid\": false, \"orient\": \"bottom\", \"labelAngle\": 270, \"labelAlign\": \"right\"}, {\"scale\": \"concat_0_y\", \"title\": \"test_acc\", \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"zindex\": 0, \"orient\": \"left\", \"grid\": false, \"labelOverlap\": true}], \"title\": {\"text\": \"Test Set Prediction Accuracy Per Epoch\", \"frame\": \"group\"}, \"style\": \"cell\"}, {\"type\": \"group\", \"name\": \"concat_1_group\", \"encode\": {\"update\": {\"width\": {\"signal\": \"childWidth\"}, \"height\": {\"signal\": \"height\"}}}, \"marks\": [{\"type\": \"group\", \"name\": \"concat_1_pathgroup\", \"from\": {\"facet\": {\"data\": \"source_1\", \"name\": \"faceted_path_concat_1_main\", \"groupby\": [\"variable\"]}}, \"encode\": {\"update\": {\"width\": {\"field\": {\"signal\": null, \"datum\": null, \"group\": \"width\", \"parent\": null}}, \"height\": {\"field\": {\"signal\": null, \"datum\": null, \"group\": \"height\", \"parent\": null}}}}, \"marks\": [{\"type\": \"line\", \"name\": \"concat_1_marks\", \"from\": {\"data\": \"faceted_path_concat_1_main\"}, \"sort\": {\"field\": \"x\"}, \"encode\": {\"update\": {\"y\": {\"field\": \"loss\", \"scale\": \"concat_1_y\"}, \"stroke\": {\"field\": \"variable\", \"scale\": \"color\"}, \"defined\": {\"signal\": \"isValid(datum[\\\"loss\\\"]) && isFinite(+datum[\\\"loss\\\"])\"}, \"x\": {\"field\": \"epoch\", \"scale\": \"concat_1_x\"}}}, \"style\": [\"line\"]}]}], \"axes\": [{\"scale\": \"concat_1_y\", \"labels\": false, \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"maxExtent\": 0, \"ticks\": false, \"zindex\": 0, \"minExtent\": 0, \"orient\": \"left\", \"aria\": false, \"gridScale\": \"concat_1_x\", \"grid\": true, \"domain\": false}, {\"scale\": \"concat_1_x\", \"labelAlign\": \"right\", \"orient\": \"bottom\", \"labelAngle\": 270, \"title\": \"epoch\", \"grid\": false, \"labelBaseline\": \"middle\", \"zindex\": 0}, {\"scale\": \"concat_1_y\", \"zindex\": 0, \"grid\": false, \"labelOverlap\": true, \"orient\": \"left\", \"title\": \"loss\", \"tickCount\": {\"signal\": \"ceil(height/40)\"}}], \"title\": {\"text\": \"Train and Test Loss Per Epoch\", \"frame\": \"group\"}, \"style\": \"cell\"}], \"scales\": [{\"name\": \"color\", \"type\": \"ordinal\", \"domain\": {\"data\": \"source_1_color_domain_variable\", \"field\": \"variable\", \"sort\": true}, \"range\": \"category\"}, {\"name\": \"concat_0_x\", \"type\": \"point\", \"domain\": {\"data\": \"source_0_concat_0_x_domain_epoch\", \"field\": \"epoch\", \"sort\": true}, \"range\": [0, {\"signal\": \"childWidth\"}], \"padding\": 0.5}, {\"name\": \"concat_0_y\", \"type\": \"linear\", \"domain\": [0.4, 1], \"range\": [{\"signal\": \"height\"}, 0], \"zero\": false}, {\"name\": \"concat_1_x\", \"type\": \"point\", \"domain\": {\"data\": \"source_1_concat_1_x_domain_epoch\", \"field\": \"epoch\", \"sort\": true}, \"range\": [0, {\"signal\": \"childWidth\"}], \"padding\": 0.5}, {\"name\": \"concat_1_y\", \"type\": \"linear\", \"domain\": [0.3, 0.57], \"range\": [{\"signal\": \"height\"}, 0], \"zero\": false}], \"padding\": 5, \"legends\": [{\"stroke\": \"color\", \"symbolType\": \"stroke\", \"title\": \"variable\"}], \"layout\": {\"padding\": 20, \"bounds\": \"full\", \"align\": \"each\"}, \"background\": \"white\", \"height\": 500}, {\"mode\": \"vega\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.HConcatChart(...)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combined data model Training"
      ],
      "metadata": {
        "id": "2yUWBnVRA_yP"
      },
      "id": "2yUWBnVRA_yP"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "2a634821",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a634821",
        "outputId": "d894af0f-050b-42df-d07a-e54dec61dacd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:17<00:00, 155.02it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 171.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.5249\n",
            " test set loss: 0.4743\n",
            " test set accuracy: 0.7723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 160.14it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 166.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4637\n",
            " test set loss: 0.452\n",
            " test set accuracy: 0.7874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 158.37it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 165.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4444\n",
            " test set loss: 0.4502\n",
            " test set accuracy: 0.7876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 161.50it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 170.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4309\n",
            " test set loss: 0.4248\n",
            " test set accuracy: 0.8041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 159.93it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 161.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4211\n",
            " test set loss: 0.4218\n",
            " test set accuracy: 0.8045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 160.85it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 163.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4134\n",
            " test set loss: 0.4086\n",
            " test set accuracy: 0.8123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 159.61it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 170.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4071\n",
            " test set loss: 0.4015\n",
            " test set accuracy: 0.8167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 157.21it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 174.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.4012\n",
            " test set loss: 0.3953\n",
            " test set accuracy: 0.8192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 158.10it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 158.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.3958\n",
            " test set loss: 0.3961\n",
            " test set accuracy: 0.819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 160.22it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 175.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.3911\n",
            " test set loss: 0.3924\n",
            " test set accuracy: 0.8213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 156.74it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 172.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.3876\n",
            " test set loss: 0.3854\n",
            " test set accuracy: 0.8245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 161.69it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 163.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.3843\n",
            " test set loss: 0.3886\n",
            " test set accuracy: 0.8223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 158.41it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 165.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.3821\n",
            " test set loss: 0.3831\n",
            " test set accuracy: 0.8275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 157.48it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 172.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.3804\n",
            " test set loss: 0.3858\n",
            " test set accuracy: 0.8239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 157.26it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 157.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.3781\n",
            " test set loss: 0.3794\n",
            " test set accuracy: 0.829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 158.48it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 168.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.3768\n",
            " test set loss: 0.3799\n",
            " test set accuracy: 0.8275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 158.60it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 163.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.3753\n",
            " test set loss: 0.3771\n",
            " test set accuracy: 0.8298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 160.88it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 162.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.3737\n",
            " test set loss: 0.379\n",
            " test set accuracy: 0.8285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 158.40it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 169.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.3727\n",
            " test set loss: 0.3759\n",
            " test set accuracy: 0.83\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 158.00it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 171.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.3709\n",
            " test set loss: 0.375\n",
            " test set accuracy: 0.8298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 160.77it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 169.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.3701\n",
            " test set loss: 0.3728\n",
            " test set accuracy: 0.8312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 160.98it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 175.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.3693\n",
            " test set loss: 0.3735\n",
            " test set accuracy: 0.8311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:17<00:00, 156.11it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 170.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.3681\n",
            " test set loss: 0.3762\n",
            " test set accuracy: 0.8306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 157.08it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 161.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.3673\n",
            " test set loss: 0.3734\n",
            " test set accuracy: 0.8317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 158.01it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 154.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.3662\n",
            " test set loss: 0.3716\n",
            " test set accuracy: 0.8309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 162.48it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 161.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.3657\n",
            " test set loss: 0.3727\n",
            " test set accuracy: 0.8313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:17<00:00, 155.52it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 164.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.3652\n",
            " test set loss: 0.3906\n",
            " test set accuracy: 0.8205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:17<00:00, 156.00it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 160.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.3646\n",
            " test set loss: 0.372\n",
            " test set accuracy: 0.8315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:17<00:00, 156.15it/s]\n",
            "100%|██████████| 665/665 [00:04<00:00, 163.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.3638\n",
            " test set loss: 0.3686\n",
            " test set accuracy: 0.8334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2659/2659 [00:16<00:00, 158.62it/s]\n",
            "100%|██████████| 665/665 [00:03<00:00, 170.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg epoch train loss: 0.3631\n",
            " test set loss: 0.3677\n",
            " test set accuracy: 0.8339\n",
            "Completed training for 30 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_ds = MethylDataset(train_parquet)\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "test_ds = MethylDataset(test_parquet)\n",
        "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "model_full = MethylCNN(sequence_length=32)\n",
        "model_full.to(device)\n",
        "\n",
        "criterion_full = nn.CrossEntropyLoss()\n",
        "optimizer_full = torch.optim.Adam(model_full.parameters(), lr=0.001)\n",
        "\n",
        "training_stats_full = train_model(model_full, train_dl, epochs = 30, criterion=criterion_full, optimizer = optimizer_full, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_loss_plot(training_stats_full)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "xKXSc2TeR27X",
        "outputId": "f924c536-c503-4f83-a3b7-2f6d7c70cf58"
      },
      "id": "xKXSc2TeR27X",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "  #altair-viz-5d9712c08a18441eaac7b91e79da8673.vega-embed {\n",
              "    width: 100%;\n",
              "    display: flex;\n",
              "  }\n",
              "\n",
              "  #altair-viz-5d9712c08a18441eaac7b91e79da8673.vega-embed details,\n",
              "  #altair-viz-5d9712c08a18441eaac7b91e79da8673.vega-embed details summary {\n",
              "    position: relative;\n",
              "  }\n",
              "</style>\n",
              "<div id=\"altair-viz-5d9712c08a18441eaac7b91e79da8673\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-5d9712c08a18441eaac7b91e79da8673\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-5d9712c08a18441eaac7b91e79da8673\");\n",
              "    }\n",
              "\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function maybeLoadScript(lib, version) {\n",
              "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
              "      return (VEGA_DEBUG[key] == version) ?\n",
              "        Promise.resolve(paths[lib]) :\n",
              "        new Promise(function(resolve, reject) {\n",
              "          var s = document.createElement('script');\n",
              "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "          s.async = true;\n",
              "          s.onload = () => {\n",
              "            VEGA_DEBUG[key] = version;\n",
              "            return resolve(paths[lib]);\n",
              "          };\n",
              "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "          s.src = paths[lib];\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      let deps = [\"vega-embed\"];\n",
              "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else {\n",
              "      maybeLoadScript(\"vega\", \"5\")\n",
              "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
              "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"$schema\": \"https://vega.github.io/schema/vega/v5.json\", \"data\": [{\"name\": \"source_0\", \"values\": [{\"epoch\": 0, \"test_acc\": 0.7723432950281632}, {\"epoch\": 1, \"test_acc\": 0.7873930839138854}, {\"epoch\": 2, \"test_acc\": 0.7876105154596768}, {\"epoch\": 3, \"test_acc\": 0.804102992034366}, {\"epoch\": 4, \"test_acc\": 0.8044732133150377}, {\"epoch\": 5, \"test_acc\": 0.8123477611896444}, {\"epoch\": 6, \"test_acc\": 0.8166552564076195}, {\"epoch\": 7, \"test_acc\": 0.8191615957124849}, {\"epoch\": 8, \"test_acc\": 0.8190146825058692}, {\"epoch\": 9, \"test_acc\": 0.8213182815856048}, {\"epoch\": 10, \"test_acc\": 0.8245033599050353}, {\"epoch\": 11, \"test_acc\": 0.8223202296547246}, {\"epoch\": 12, \"test_acc\": 0.8275033275841298}, {\"epoch\": 13, \"test_acc\": 0.823942151455763}, {\"epoch\": 14, \"test_acc\": 0.8289518918013616}, {\"epoch\": 15, \"test_acc\": 0.8274739449428067}, {\"epoch\": 16, \"test_acc\": 0.8298451240975856}, {\"epoch\": 17, \"test_acc\": 0.8284553251630002}, {\"epoch\": 18, \"test_acc\": 0.8299949755683338}, {\"epoch\": 19, \"test_acc\": 0.8298098649279978}, {\"epoch\": 20, \"test_acc\": 0.8312407995604357}, {\"epoch\": 21, \"test_acc\": 0.8310938863538199}, {\"epoch\": 22, \"test_acc\": 0.8306061345078555}, {\"epoch\": 23, \"test_acc\": 0.8317226748781354}, {\"epoch\": 24, \"test_acc\": 0.8309117139776163}, {\"epoch\": 25, \"test_acc\": 0.8313436388050668}, {\"epoch\": 26, \"test_acc\": 0.8204838145720271}, {\"epoch\": 27, \"test_acc\": 0.8314934902758149}, {\"epoch\": 28, \"test_acc\": 0.8334474359238049}, {\"epoch\": 29, \"test_acc\": 0.8338793607512553}]}, {\"name\": \"source_1\", \"values\": [{\"epoch\": 0, \"variable\": \"train_loss\", \"loss\": 0.5249248149812826}, {\"epoch\": 1, \"variable\": \"train_loss\", \"loss\": 0.46372312139236377}, {\"epoch\": 2, \"variable\": \"train_loss\", \"loss\": 0.4444060780110777}, {\"epoch\": 3, \"variable\": \"train_loss\", \"loss\": 0.43088656992291813}, {\"epoch\": 4, \"variable\": \"train_loss\", \"loss\": 0.4211040947974378}, {\"epoch\": 5, \"variable\": \"train_loss\", \"loss\": 0.4133940705032714}, {\"epoch\": 6, \"variable\": \"train_loss\", \"loss\": 0.40708480950762965}, {\"epoch\": 7, \"variable\": \"train_loss\", \"loss\": 0.40120796615488324}, {\"epoch\": 8, \"variable\": \"train_loss\", \"loss\": 0.3957838268937272}, {\"epoch\": 9, \"variable\": \"train_loss\", \"loss\": 0.3910908673144947}, {\"epoch\": 10, \"variable\": \"train_loss\", \"loss\": 0.3875807710678428}, {\"epoch\": 11, \"variable\": \"train_loss\", \"loss\": 0.3842809091232109}, {\"epoch\": 12, \"variable\": \"train_loss\", \"loss\": 0.3821409289865576}, {\"epoch\": 13, \"variable\": \"train_loss\", \"loss\": 0.38038001818377165}, {\"epoch\": 14, \"variable\": \"train_loss\", \"loss\": 0.3781263242654668}, {\"epoch\": 15, \"variable\": \"train_loss\", \"loss\": 0.37679396458208314}, {\"epoch\": 16, \"variable\": \"train_loss\", \"loss\": 0.3752755374893204}, {\"epoch\": 17, \"variable\": \"train_loss\", \"loss\": 0.37365134631435243}, {\"epoch\": 18, \"variable\": \"train_loss\", \"loss\": 0.37272495540204287}, {\"epoch\": 19, \"variable\": \"train_loss\", \"loss\": 0.3708835245972067}, {\"epoch\": 20, \"variable\": \"train_loss\", \"loss\": 0.37007279177947616}, {\"epoch\": 21, \"variable\": \"train_loss\", \"loss\": 0.36934120770951506}, {\"epoch\": 22, \"variable\": \"train_loss\", \"loss\": 0.36805857137972003}, {\"epoch\": 23, \"variable\": \"train_loss\", \"loss\": 0.3672553040717678}, {\"epoch\": 24, \"variable\": \"train_loss\", \"loss\": 0.3661819926416484}, {\"epoch\": 25, \"variable\": \"train_loss\", \"loss\": 0.365712111731049}, {\"epoch\": 26, \"variable\": \"train_loss\", \"loss\": 0.36515633455341406}, {\"epoch\": 27, \"variable\": \"train_loss\", \"loss\": 0.3645545770997345}, {\"epoch\": 28, \"variable\": \"train_loss\", \"loss\": 0.3638364182082546}, {\"epoch\": 29, \"variable\": \"train_loss\", \"loss\": 0.36311453867783533}, {\"epoch\": 0, \"variable\": \"test_loss\", \"loss\": 0.4743482269610707}, {\"epoch\": 1, \"variable\": \"test_loss\", \"loss\": 0.451982077138034}, {\"epoch\": 2, \"variable\": \"test_loss\", \"loss\": 0.4502104603826222}, {\"epoch\": 3, \"variable\": \"test_loss\", \"loss\": 0.42475725401477177}, {\"epoch\": 4, \"variable\": \"test_loss\", \"loss\": 0.4217915636156047}, {\"epoch\": 5, \"variable\": \"test_loss\", \"loss\": 0.4085933455789554}, {\"epoch\": 6, \"variable\": \"test_loss\", \"loss\": 0.4014858090244983}, {\"epoch\": 7, \"variable\": \"test_loss\", \"loss\": 0.3953076903925651}, {\"epoch\": 8, \"variable\": \"test_loss\", \"loss\": 0.3960610847283972}, {\"epoch\": 9, \"variable\": \"test_loss\", \"loss\": 0.39240226825997315}, {\"epoch\": 10, \"variable\": \"test_loss\", \"loss\": 0.3853855527767948}, {\"epoch\": 11, \"variable\": \"test_loss\", \"loss\": 0.3886159730673109}, {\"epoch\": 12, \"variable\": \"test_loss\", \"loss\": 0.38309762549448595}, {\"epoch\": 13, \"variable\": \"test_loss\", \"loss\": 0.38577075369278824}, {\"epoch\": 14, \"variable\": \"test_loss\", \"loss\": 0.3794233831307857}, {\"epoch\": 15, \"variable\": \"test_loss\", \"loss\": 0.3799092355476854}, {\"epoch\": 16, \"variable\": \"test_loss\", \"loss\": 0.37712362663493276}, {\"epoch\": 17, \"variable\": \"test_loss\", \"loss\": 0.37899187730750616}, {\"epoch\": 18, \"variable\": \"test_loss\", \"loss\": 0.37590998782927176}, {\"epoch\": 19, \"variable\": \"test_loss\", \"loss\": 0.37500786712229356}, {\"epoch\": 20, \"variable\": \"test_loss\", \"loss\": 0.3727960579619543}, {\"epoch\": 21, \"variable\": \"test_loss\", \"loss\": 0.37346706032429344}, {\"epoch\": 22, \"variable\": \"test_loss\", \"loss\": 0.3761688515725596}, {\"epoch\": 23, \"variable\": \"test_loss\", \"loss\": 0.37341430912214335}, {\"epoch\": 24, \"variable\": \"test_loss\", \"loss\": 0.3716036266134073}, {\"epoch\": 25, \"variable\": \"test_loss\", \"loss\": 0.3727124072668141}, {\"epoch\": 26, \"variable\": \"test_loss\", \"loss\": 0.3906230289577769}, {\"epoch\": 27, \"variable\": \"test_loss\", \"loss\": 0.3719742649500573}, {\"epoch\": 28, \"variable\": \"test_loss\", \"loss\": 0.3686007910711475}, {\"epoch\": 29, \"variable\": \"test_loss\", \"loss\": 0.36769360339404755}]}, {\"name\": \"source_1_color_domain_variable\", \"values\": [{\"variable\": \"train_loss\"}, {\"variable\": \"test_loss\"}]}, {\"name\": \"source_0_concat_0_x_domain_epoch\", \"values\": [{\"epoch\": 0}, {\"epoch\": 1}, {\"epoch\": 2}, {\"epoch\": 3}, {\"epoch\": 4}, {\"epoch\": 5}, {\"epoch\": 6}, {\"epoch\": 7}, {\"epoch\": 8}, {\"epoch\": 9}, {\"epoch\": 10}, {\"epoch\": 11}, {\"epoch\": 12}, {\"epoch\": 13}, {\"epoch\": 14}, {\"epoch\": 15}, {\"epoch\": 16}, {\"epoch\": 17}, {\"epoch\": 18}, {\"epoch\": 19}, {\"epoch\": 20}, {\"epoch\": 21}, {\"epoch\": 22}, {\"epoch\": 23}, {\"epoch\": 24}, {\"epoch\": 25}, {\"epoch\": 26}, {\"epoch\": 27}, {\"epoch\": 28}, {\"epoch\": 29}]}, {\"name\": \"source_1_concat_1_x_domain_epoch\", \"values\": [{\"epoch\": 0}, {\"epoch\": 1}, {\"epoch\": 2}, {\"epoch\": 3}, {\"epoch\": 4}, {\"epoch\": 5}, {\"epoch\": 6}, {\"epoch\": 7}, {\"epoch\": 8}, {\"epoch\": 9}, {\"epoch\": 10}, {\"epoch\": 11}, {\"epoch\": 12}, {\"epoch\": 13}, {\"epoch\": 14}, {\"epoch\": 15}, {\"epoch\": 16}, {\"epoch\": 17}, {\"epoch\": 18}, {\"epoch\": 19}, {\"epoch\": 20}, {\"epoch\": 21}, {\"epoch\": 22}, {\"epoch\": 23}, {\"epoch\": 24}, {\"epoch\": 25}, {\"epoch\": 26}, {\"epoch\": 27}, {\"epoch\": 28}, {\"epoch\": 29}]}], \"signals\": [{\"name\": \"childWidth\", \"value\": 700}], \"marks\": [{\"type\": \"group\", \"name\": \"concat_0_group\", \"encode\": {\"update\": {\"height\": {\"signal\": \"height\"}, \"width\": {\"signal\": \"childWidth\"}}}, \"marks\": [{\"type\": \"line\", \"name\": \"concat_0_marks\", \"from\": {\"data\": \"source_0\"}, \"sort\": {\"field\": \"x\"}, \"encode\": {\"update\": {\"x\": {\"field\": \"epoch\", \"scale\": \"concat_0_x\"}, \"stroke\": {\"value\": \"#4c78a8\"}, \"y\": {\"field\": \"test_acc\", \"scale\": \"concat_0_y\"}, \"defined\": {\"signal\": \"isValid(datum[\\\"test_acc\\\"]) && isFinite(+datum[\\\"test_acc\\\"])\"}}}, \"style\": [\"line\"]}], \"axes\": [{\"scale\": \"concat_0_y\", \"maxExtent\": 0, \"grid\": true, \"labels\": false, \"ticks\": false, \"orient\": \"left\", \"gridScale\": \"concat_0_x\", \"zindex\": 0, \"minExtent\": 0, \"aria\": false, \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"domain\": false}, {\"scale\": \"concat_0_x\", \"title\": \"epoch\", \"labelAlign\": \"right\", \"labelAngle\": 270, \"orient\": \"bottom\", \"labelBaseline\": \"middle\", \"zindex\": 0, \"grid\": false}, {\"scale\": \"concat_0_y\", \"labelOverlap\": true, \"orient\": \"left\", \"title\": \"test_acc\", \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"grid\": false, \"zindex\": 0}], \"title\": {\"text\": \"Test Set Prediction Accuracy Per Epoch\", \"frame\": \"group\"}, \"style\": \"cell\"}, {\"type\": \"group\", \"name\": \"concat_1_group\", \"encode\": {\"update\": {\"width\": {\"signal\": \"childWidth\"}, \"height\": {\"signal\": \"height\"}}}, \"marks\": [{\"type\": \"group\", \"name\": \"concat_1_pathgroup\", \"from\": {\"facet\": {\"data\": \"source_1\", \"name\": \"faceted_path_concat_1_main\", \"groupby\": [\"variable\"]}}, \"encode\": {\"update\": {\"height\": {\"field\": {\"signal\": null, \"datum\": null, \"group\": \"height\", \"parent\": null}}, \"width\": {\"field\": {\"signal\": null, \"datum\": null, \"group\": \"width\", \"parent\": null}}}}, \"marks\": [{\"type\": \"line\", \"name\": \"concat_1_marks\", \"from\": {\"data\": \"faceted_path_concat_1_main\"}, \"sort\": {\"field\": \"x\"}, \"encode\": {\"update\": {\"stroke\": {\"field\": \"variable\", \"scale\": \"color\"}, \"x\": {\"field\": \"epoch\", \"scale\": \"concat_1_x\"}, \"y\": {\"field\": \"loss\", \"scale\": \"concat_1_y\"}, \"defined\": {\"signal\": \"isValid(datum[\\\"loss\\\"]) && isFinite(+datum[\\\"loss\\\"])\"}}}, \"style\": [\"line\"]}]}], \"axes\": [{\"scale\": \"concat_1_y\", \"zindex\": 0, \"ticks\": false, \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"aria\": false, \"orient\": \"left\", \"domain\": false, \"maxExtent\": 0, \"grid\": true, \"gridScale\": \"concat_1_x\", \"labels\": false, \"minExtent\": 0}, {\"scale\": \"concat_1_x\", \"labelAngle\": 270, \"zindex\": 0, \"labelBaseline\": \"middle\", \"grid\": false, \"title\": \"epoch\", \"orient\": \"bottom\", \"labelAlign\": \"right\"}, {\"scale\": \"concat_1_y\", \"zindex\": 0, \"labelOverlap\": true, \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"title\": \"loss\", \"orient\": \"left\", \"grid\": false}], \"title\": {\"text\": \"Train and Test Loss Per Epoch\", \"frame\": \"group\"}, \"style\": \"cell\"}], \"scales\": [{\"name\": \"color\", \"type\": \"ordinal\", \"domain\": {\"data\": \"source_1_color_domain_variable\", \"field\": \"variable\", \"sort\": true}, \"range\": \"category\"}, {\"name\": \"concat_0_x\", \"type\": \"point\", \"domain\": {\"data\": \"source_0_concat_0_x_domain_epoch\", \"field\": \"epoch\", \"sort\": true}, \"range\": [0, {\"signal\": \"childWidth\"}], \"padding\": 0.5}, {\"name\": \"concat_0_y\", \"type\": \"linear\", \"domain\": [0.4, 1], \"range\": [{\"signal\": \"height\"}, 0], \"zero\": false}, {\"name\": \"concat_1_x\", \"type\": \"point\", \"domain\": {\"data\": \"source_1_concat_1_x_domain_epoch\", \"field\": \"epoch\", \"sort\": true}, \"range\": [0, {\"signal\": \"childWidth\"}], \"padding\": 0.5}, {\"name\": \"concat_1_y\", \"type\": \"linear\", \"domain\": [0.3, 0.57], \"range\": [{\"signal\": \"height\"}, 0], \"zero\": false}], \"background\": \"white\", \"height\": 500, \"padding\": 5, \"layout\": {\"padding\": 20, \"bounds\": \"full\", \"align\": \"each\"}, \"legends\": [{\"stroke\": \"color\", \"symbolType\": \"stroke\", \"title\": \"variable\"}]}, {\"mode\": \"vega\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.HConcatChart(...)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "db55dd21",
      "metadata": {
        "id": "db55dd21"
      },
      "outputs": [],
      "source": [
        "# with torch.no_grad():\n",
        "#     model_full.eval()\n",
        "#     batch = next(iter(train_dl))\n",
        "#     labels = batch.pop('label').to(device)\n",
        "#     inputs: Dict[str, torch.Tensor] = {\n",
        "#                 k: v.to(device) for k, v in batch.items()\n",
        "#             }\n",
        "\n",
        "#     print(model_full(inputs), labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save(model, '/content/gdrive/MyDrive/methylation/models/methyl_cnn_v0.pt')"
      ],
      "metadata": {
        "id": "f9Iql9og5DB4"
      },
      "id": "f9Iql9og5DB4",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save({\n",
        "#             'epoch': epoch,\n",
        "#             'model_state_dict': model.state_dict(),\n",
        "#             'optimizer_state_dict': optimizer.state_dict(),\n",
        "#             'loss': loss\n",
        "#             }, '/content/gdrive/MyDrive/methylation/models/methyl_cnn_v0_full.pt')"
      ],
      "metadata": {
        "id": "ylWoa3ec6fgS"
      },
      "id": "ylWoa3ec6fgS",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "VzBYWT6xJhTt",
      "metadata": {
        "id": "VzBYWT6xJhTt"
      },
      "source": [
        "# Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95aeec77",
      "metadata": {
        "id": "95aeec77"
      },
      "source": [
        "### test 1:\n",
        "0.815 test set accuracy\n",
        "### test 2:\n",
        "move from adam -> adam2, change conv1 to size 5\n",
        "0.808 test set accuracy\n",
        "0.807 train set accuracy (why is this lower than the train set accuracy??)\n",
        "### test 3:\n",
        "add another convolutional layer (64-> 128)\n",
        "test set\n",
        "train set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_load_test = model = MethylCNN(sequence_length=32)"
      ],
      "metadata": {
        "id": "poUine3W6S9Q"
      },
      "id": "poUine3W6S9Q",
      "execution_count": 29,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}